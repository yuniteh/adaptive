{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gpu import set_gpu\n",
    "import numpy as np\n",
    "import os\n",
    "import adapt.utils.data_utils as prd\n",
    "import adapt.loop as lp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import adapt.ml.dl_subclass as dl\n",
    "import tensorflow as tf\n",
    "\n",
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/yteh/Documents/work/necal/home data/TR58/DATA/MAT/'\n",
    "all_files = os.listdir(path)\n",
    "train_file = all_files[0]\n",
    "train_file2 = all_files[1]\n",
    "ft= 'feat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = np.delete(all_files,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_params = prd.load_caps_train(path + train_file + '/traindata.mat')\n",
    "train_data = train_data[:,:8,:]\n",
    "\n",
    "train_dof = np.unique(train_params[:,2])\n",
    "key = np.empty(train_dof.shape)\n",
    "for i in range(len(train_dof)):\n",
    "    key[i] = train_params[np.argmax(train_params[:,2] == train_dof[i]),0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2, train_params2 = prd.load_caps_train(path + train_file2 + '/traindata.mat')\n",
    "train_data2 = train_data2[:,:8,:]\n",
    "train_data = np.vstack((train_data,train_data2))\n",
    "train_params = np.vstack((train_params,train_params2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep initial training data\n",
    "ep = 50\n",
    "n_dof = len(train_dof)\n",
    "\n",
    "trainmlp_0, traincnn_0, y_train_0, x_train_mlp_0, x_train_cnn_0, x_train_lda_0, y_train_lda_0, emg_scale, scaler, _, _, _ = prd.prep_train_caps(train_data, train_params, prop_b = False, batch_size=128,ft=ft, noise=True)\n",
    "y_test_0, x_test_mlp_0, x_test_cnn_0, x_lda_0, y_lda_0 = prd.prep_test_caps(train_data, train_params, scaler, emg_scale, num_classes=len(train_dof),ft=ft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial training\n",
    "mlp, cnn, w, c = lp.train_models(traincnn_0, trainmlp_0, x_train_lda_0, y_train_lda_0, n_dof, ep=ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set: 20170730_054913 CNN Accuracy: 67.52, MLP Accuracy: 70.13, LDA Accuracy: 68.52\n",
      "Set: 20170730_055812 CNN Accuracy: 68.05, MLP Accuracy: 71.97, LDA Accuracy: 73.77\n",
      "Set: 20170730_060537 CNN Accuracy: 60.84, MLP Accuracy: 62.90, LDA Accuracy: 70.14\n",
      "Set: 20170730_123937 CNN Accuracy: 62.62, MLP Accuracy: 60.94, LDA Accuracy: 67.58\n",
      "Set: 20170731_123147 CNN Accuracy: 64.42, MLP Accuracy: 67.74, LDA Accuracy: 54.48\n",
      "Set: 20170801_053500 CNN Accuracy: 61.80, MLP Accuracy: 61.06, LDA Accuracy: 55.77\n",
      "Set: 20170801_054938 CNN Accuracy: 61.39, MLP Accuracy: 62.73, LDA Accuracy: 64.22\n",
      "Set: 20170801_065547 CNN Accuracy: 61.88, MLP Accuracy: 66.08, LDA Accuracy: 64.10\n",
      "Set: 20170802_050945 CNN Accuracy: 62.27, MLP Accuracy: 63.91, LDA Accuracy: 63.83\n",
      "Set: 20170802_051732 CNN Accuracy: 66.42, MLP Accuracy: 63.66, LDA Accuracy: 63.61\n",
      "Set: 20170802_052140 CNN Accuracy: 65.80, MLP Accuracy: 68.50, LDA Accuracy: 68.87\n",
      "Set: 20170807_153152 CNN Accuracy: 56.91, MLP Accuracy: 59.04, LDA Accuracy: 55.40\n",
      "Set: 20170807_153559 CNN Accuracy: 49.67, MLP Accuracy: 50.39, LDA Accuracy: 56.61\n",
      "Set: 20170808_054353 CNN Accuracy: 61.60, MLP Accuracy: 67.28, LDA Accuracy: 58.59\n",
      "Set: 20170808_063929 CNN Accuracy: 67.48, MLP Accuracy: 70.24, LDA Accuracy: 69.42\n",
      "Set: 20170808_104400 CNN Accuracy: 64.48, MLP Accuracy: 62.77, LDA Accuracy: 62.34\n",
      "Missing classes\n",
      "Set: 20170913_053927 CNN Accuracy: 56.36, MLP Accuracy: 34.91, LDA Accuracy: 9.53\n",
      "Missing classes\n",
      "Set: 20170913_061042 CNN Accuracy: 81.37, MLP Accuracy: 79.99, LDA Accuracy: 67.71\n",
      "Missing classes\n",
      "Set: 20170915_173323 CNN Accuracy: 46.30, MLP Accuracy: 36.86, LDA Accuracy: 18.75\n",
      "Missing classes\n",
      "Set: 20170916_161424 CNN Accuracy: 75.45, MLP Accuracy: 80.93, LDA Accuracy: 57.99\n",
      "Missing classes\n",
      "Set: 20170923_073346 CNN Accuracy: 62.25, MLP Accuracy: 56.83, LDA Accuracy: 55.42\n",
      "Missing classes\n",
      "Set: 20170929_051442 CNN Accuracy: 54.27, MLP Accuracy: 49.17, LDA Accuracy: 53.47\n"
     ]
    }
   ],
   "source": [
    "# Test all controllers without recalibration or adaptation\n",
    "acc = np.empty((len(all_files),4))\n",
    "\n",
    "for i in range(1,len(all_files)):\n",
    "    # load data\n",
    "    test_file = all_files[i]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data,test_params,train_dof,key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=len(train_dof),ft=ft)\n",
    "    acc[i,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, [w, c])\n",
    "    print ('Set: ' + test_file, f'CNN Accuracy: {acc[i,2]:.2f},', f'MLP Accuracy: {acc[i,1]:.2f},', f'LDA Accuracy: {acc[i,0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial train acc: 0.1594, val acc 0: 0.1273\n",
      "Final train acc: 0.6680,  val acc 0: 0.7216\n",
      "Initial train acc: 0.6263, val acc 0: 0.7216, val acc 1: 0.6989\n",
      "Final train acc: 0.7759,  val acc 0: 0.7148, val acc 1: 0.8473\n",
      "EWC: 20170730_054913, Test: 20170730_055812 , EWC Accuracy: 80.25 , CNN Accuracy: 82.62, MLP Accuracy: 75.65, LDA Accuracy: 79.62\n",
      "Initial train acc: 0.6987, val acc 0: 0.8473, val acc 1: 0.7449\n",
      "Final train acc: 0.7286,  val acc 0: 0.8174, val acc 1: 0.7874\n",
      "EWC: 20170730_060537, Test: 20170730_123937 , EWC Accuracy: 67.19 , CNN Accuracy: 77.52, MLP Accuracy: 76.98, LDA Accuracy: 79.34\n",
      "Initial train acc: 0.6347, val acc 0: 0.7874, val acc 1: 0.6615\n",
      "Final train acc: 0.6991,  val acc 0: 0.7397, val acc 1: 0.7548\n",
      "EWC: 20170731_123147, Test: 20170801_053500 , EWC Accuracy: 69.28 , CNN Accuracy: 62.23, MLP Accuracy: 58.30, LDA Accuracy: 61.06\n",
      "Initial train acc: 0.6838, val acc 0: 0.7548, val acc 1: 0.7053\n",
      "Final train acc: 0.8188,  val acc 0: 0.4965, val acc 1: 0.8558\n",
      "EWC: 20170801_054938, Test: 20170801_065547 , EWC Accuracy: 60.01 , CNN Accuracy: 48.50, MLP Accuracy: 44.70, LDA Accuracy: 45.89\n",
      "Initial train acc: 0.7629, val acc 0: 0.8558, val acc 1: 0.7979\n",
      "Final train acc: 0.8302,  val acc 0: 0.7644, val acc 1: 0.8688\n",
      "EWC: 20170802_050945, Test: 20170802_051732 , EWC Accuracy: 57.12 , CNN Accuracy: 46.52, MLP Accuracy: 51.68, LDA Accuracy: 54.91\n",
      "Initial train acc: 0.7693, val acc 0: 0.8688, val acc 1: 0.8136\n",
      "Final train acc: 0.8711,  val acc 0: 0.7785, val acc 1: 0.9012\n"
     ]
    }
   ],
   "source": [
    "# Test all controllers with ewc\n",
    "ep = 50\n",
    "# Remove extra file if odd number of files\n",
    "if len(all_files)%2 == 0:\n",
    "    all_files = np.delete(all_files,-1)\n",
    "ewc_acc = np.empty((len(all_files),4))\n",
    "ewc_acc[:] = np.nan\n",
    "n_dof = len(train_dof)\n",
    "\n",
    "ewc = dl.EWC()\n",
    "ewc(x_train_mlp_0[:1,...])\n",
    "loss, fish_loss = lp.train_task(ewc, ep, 1, x_train_mlp_0,y_train_0, [x_test_mlp_0],[y_test_0], lams=[0])\n",
    "x_train_ewc = x_train_mlp_0\n",
    "y_train_ewc = y_train_0\n",
    "\n",
    "for i in range(1,len(all_files)-1,2):\n",
    "    # load recalibration data\n",
    "    ewc_file = all_files[i]\n",
    "    ewc_data, ewc_params = prd.load_caps_train(path + ewc_file + '/traindata.mat')\n",
    "    ewc_data = ewc_data[:,:8,:]\n",
    "\n",
    "    ewc.compute_fisher(x_train_ewc, y_train_ewc, num_samples=200, plot_diffs=True) # use validation set for Fisher computation\n",
    "    ewc.star()\n",
    "\n",
    "    # check class labels\n",
    "    ewc_data, ewc_params = lp.check_labels(ewc_data, ewc_params, train_dof, key)\n",
    "    \n",
    "    ewcmlp, ewccnn, y_train_ewc, x_train_ewc, _, x_train_lda, y_train_lda, _, _, _, _, _ = prd.prep_train_caps(ewc_data, ewc_params, prop_b = False, num_classes=n_dof, batch_size=32, noise=True, scaler=scaler, emg_scale=emg_scale,ft=ft)\n",
    "    y_test_ewc, x_test_ewc, _, _, _ = prd.prep_test_caps(ewc_data, ewc_params, scaler, emg_scale, num_classes=n_dof,ft=ft)\n",
    "\n",
    "    loss, fish_loss = lp.train_task(ewc, 30, 1, x_train_ewc,y_train_ewc, [x_test_mlp_0, x_test_ewc], [y_test_0, y_test_ewc], lams=[10])#,15,50])\n",
    "    mlp, cnn, w, c = lp.train_models(ewccnn, ewcmlp, x_train_lda, y_train_lda, n_dof, 30, mlp, cnn)\n",
    "\n",
    "    # load test data\n",
    "    test_file = all_files[i+1]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data, test_params, train_dof, key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=n_dof,ft=ft)\n",
    "    ewc_acc[i+1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, [w, c], ewc)\n",
    "\n",
    "    x_test_mlp_0 = x_test_ewc\n",
    "    y_test_0 = y_test_ewc\n",
    "\n",
    "    print ('EWC: ' + ewc_file + ', Test: ' + test_file + ',', f'EWC Accuracy: {ewc_acc[i+1,3]:.2f},', f'CNN Accuracy: {ewc_acc[i+1,2]:.2f},', f'MLP Accuracy: {ewc_acc[i+1,1]:.2f},', f'LDA Accuracy: {ewc_acc[i+1,0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all controllers with adaptation\n",
    "ep = 5\n",
    "# Remove extra file if odd number of files\n",
    "if len(all_files)%2 == 0:\n",
    "    all_files = np.delete(all_files,-1)\n",
    "adapt_acc = np.empty((len(all_files),3))\n",
    "adapt_acc[:] = np.nan\n",
    "n_dof = len(train_dof)\n",
    "\n",
    "for i in range(1,len(all_files)-1,2):\n",
    "    # load recalibration data\n",
    "    adapt_file = all_files[i]\n",
    "    adapt_data, adapt_params = prd.load_caps_train(path + adapt_file + '/traindata.mat')\n",
    "    adapt_data = adapt_data[:,:8,:]\n",
    "\n",
    "    # check class labels\n",
    "    adapt_data, adapt_params = lp.check_labels(adapt_data, adapt_params, train_dof, key)\n",
    "    \n",
    "    adaptmlp, adaptcnn, _, _, _, x_train_lda, y_train_lda, emg_scale, scaler, _, _, _ = prd.prep_train_caps(adapt_data, adapt_params, prop_b = False, num_classes=n_dof, batch_size=16, noise=True, scaler=scaler, emg_scale=emg_scale,ft=ft)\n",
    "    mlp, cnn, w, c = lp.train_models(adaptcnn, adaptmlp, x_train_lda, y_train_lda, n_dof, ep, mlp, cnn)\n",
    "    \n",
    "    # load data\n",
    "    test_file = all_files[i+1]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data, test_params, train_dof, key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=n_dof,ft=ft)\n",
    "    adapt_acc[i+1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, [w, c])\n",
    "\n",
    "    print ('Adapt: ' + adapt_file + ', Test: ' + test_file, f', CNN Accuracy: {adapt_acc[i+1,2]:.2f},', f'MLP Accuracy: {adapt_acc[i+1,1]:.2f},', f'LDA Accuracy: {adapt_acc[i+1,0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all controllers with recalibration\n",
    "ep = 30\n",
    "# Remove extra file if odd number of files\n",
    "if len(all_files)%2 == 0:\n",
    "    all_files = np.delete(all_files,-1)\n",
    "recal_acc = np.empty((len(all_files),3))\n",
    "recal_acc[:] = np.nan\n",
    "\n",
    "for i in range(1,len(all_files)-1,2):\n",
    "    # load recalibration data\n",
    "    recal_file = all_files[i]\n",
    "    recal_data, recal_params = prd.load_caps_train(path + recal_file + '/traindata.mat')\n",
    "    recal_data = recal_data[:,:8,:]\n",
    "\n",
    "    recal_dof = np.unique(recal_params[:,2])\n",
    "    recal_key = np.empty(recal_dof.shape)\n",
    "    for dof_i in range(len(recal_dof)):\n",
    "        recal_key[dof_i] = recal_params[np.argmax(recal_params[:,2] == recal_dof[dof_i]),0]\n",
    "    n_recal_dof = len(recal_dof)\n",
    "    \n",
    "    recalmlp, recalcnn, _, _, _, x_train_lda, y_train_lda, emg_scale, scaler, _, _, _ = prd.prep_train_caps(recal_data, recal_params, prop_b = False,ft=ft,batch_size=32)\n",
    "    mlp, cnn, w, c = lp.train_models(recalcnn, recalmlp, x_train_lda, y_train_lda, n_recal_dof, ep)\n",
    "    \n",
    "    # load data\n",
    "    test_file = all_files[i+1]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data,test_params,recal_dof,recal_key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=n_recal_dof,ft=ft)\n",
    "    recal_acc[i+1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, [w, c])\n",
    "\n",
    "    print ('Recal: ' + recal_file + ', Test: ' + test_file, f', CNN Accuracy: {recal_acc[i+1,2]:.2f},', f'MLP Accuracy: {recal_acc[i+1,1]:.2f},', f'LDA Accuracy: {recal_acc[i+1,0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all controllers with adaptation\n",
    "ep = 15\n",
    "# Remove extra file if odd number of files\n",
    "if len(all_files)%2 == 0:\n",
    "    all_files = np.delete(all_files,-1)\n",
    "align_acc = np.empty((len(all_files),3))\n",
    "align_acc[:] = np.nan\n",
    "n_dof = len(train_dof)\n",
    "\n",
    "for i in range(1,len(all_files)-1,2):\n",
    "    # load recalibration data\n",
    "    align_file = all_files[i]\n",
    "    align_data, align_params = prd.load_caps_train(path + align_file + '/traindata.mat')\n",
    "    align_data = align_data[:,:8,:]\n",
    "\n",
    "    # check class labels\n",
    "    align_data, align_params = lp.check_labels(align_data, align_params, train_dof, key)\n",
    "    \n",
    "    alignmlp, aligncnn, _, _, _, x_train_lda, y_train_lda, emg_scale, scaler, _, _, _ = prd.prep_train_caps(align_data, align_params, prop_b = False, num_classes=n_dof, batch_size=64, noise=True, scaler=scaler, emg_scale=emg_scale,ft=ft)\n",
    "    mlp, cnn, mlp_ali, cnn_ali, w, c = lp.train_models(aligncnn, alignmlp, x_train_lda, y_train_lda, n_dof, ep, mlp, cnn, align=True)\n",
    "    \n",
    "    # load data\n",
    "    test_file = all_files[i+1]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data, test_params, train_dof, key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=n_dof,ft=ft)\n",
    "    align_acc[i+1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, [w, c], cnn_align=cnn_ali, mlp_align=mlp_ali)\n",
    "\n",
    "    print ('Align: ' + align_file + ', Test: ' + test_file, f', CNN Accuracy: {align_acc[i+1,2]:.2f},', f'MLP Accuracy: {align_acc[i+1,1]:.2f},', f'LDA Accuracy: {align_acc[i+1,0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if acc.shape[0] > recal_acc.shape[0]:\n",
    "    acc = np.delete(acc,-1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors =  cm.get_cmap('tab20c')\n",
    "c = np.empty((20,4))\n",
    "for i in range(20):\n",
    "    c[i,:] = colors(i*1/20)\n",
    "col = np.empty((7,4))\n",
    "col[0,:] = np.array([0,0,0,1])\n",
    "col[1,:] = c[8,:]\n",
    "col[2,:] = c[0,:]\n",
    "col[3,:] = c[9,:]\n",
    "col[4,:] = c[1,:]\n",
    "col[5,:] = c[10,:]\n",
    "col[6,:] = c[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in range(1,3):\n",
    "    nnVlda = acc[:,mod] - acc[:,0]\n",
    "    annVlda = adapt_acc[:,mod] - acc[:,0]\n",
    "    rnnVlda = recal_acc[:,mod] - acc[:,0]\n",
    "    nnVrlda = acc[:,mod] - recal_acc[:,0]\n",
    "    annVrlda = adapt_acc[:,mod] - adapt_acc[:,0]\n",
    "    rnnVrlda = recal_acc[:,mod] - recal_acc[:,0]\n",
    "    mask = ~np.isnan(annVrlda)\n",
    "    \n",
    "    fig,ax = plt.subplots(1,3,figsize=(16,4))\n",
    "\n",
    "    ax[0].plot(acc[mask,0],'o-',color=col[0,:])\n",
    "    ax[0].plot(recal_acc[mask,0], 'o--',color=col[0,:])\n",
    "    ax[0].plot(acc[mask,mod],'o-',color=col[mod,:])\n",
    "    ax[0].plot(recal_acc[mask,mod], 's-',color=col[mod+2,:])\n",
    "    ax[0].plot(adapt_acc[mask,mod], 'v-',color=col[mod+4,:])\n",
    "    if mod == 1:\n",
    "        ax[0].legend(['LDA', 'r-LDA', 'MLP', 'r-MLP', 'a-MLP', ])\n",
    "    else:\n",
    "        ax[0].legend(['LDA', 'r-LDA', 'CNN', 'r-CNN', 'a-CNN'])\n",
    "    ax[0].set_ylim([0,100])\n",
    "\n",
    "    ax[1].plot(nnVrlda[mask],'o-',color=col[mod,:])\n",
    "    ax[1].plot(rnnVrlda[mask],'s-',color=col[mod+2,:])\n",
    "    ax[1].plot(annVrlda[mask],'v-',color=col[mod+4,:])\n",
    "    if mod == 1:\n",
    "        ax[1].legend(['MLP vs. r-LDA', 'r-MLP vs. r-LDA', 'a-MLP vs. r-LDA'])\n",
    "    else:\n",
    "        ax[1].legend(['CNN vs. r-LDA', 'r-CNN vs. r-LDA', 'a-CNN vs. r-LDA'])\n",
    "    ax[1].axhline(0, ls = '--',color='black')\n",
    "\n",
    "    ax[2].plot(nnVlda[mask],'o-',color=col[mod,:])\n",
    "    ax[2].plot(rnnVlda[mask],'s-',color=col[mod+2,:])\n",
    "    ax[2].plot(annVlda[mask],'v-',color=col[mod+4,:])\n",
    "    if mod == 1:\n",
    "        ax[2].legend(['MLP vs. LDA', 'r-MLP vs. LDA', 'a-MLP vs. LDA'])\n",
    "    else:\n",
    "        ax[2].legend(['CNN vs. LDA', 'r-CNN vs. LDA', 'a-CNN vs. LDA'])\n",
    "    ax[2].axhline(0, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(16,4))\n",
    "x = range(0,acc.shape[0]-2,1)\n",
    "x_skip = range(0,acc.shape[0]-2,2)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[0].plot(x_skip,acc[2::2,i],'o',color=col[i,:], label='_nolegend_')\n",
    "    ax[0].plot(x,acc[2:,i],'-',color=col[i,:])\n",
    "\n",
    "    if i == 0:\n",
    "        ls = 's--'\n",
    "    else:\n",
    "        ls = 's-'\n",
    "    ax[1].plot(x_skip,recal_acc[mask,i], ls,color=col[i,:])\n",
    "\n",
    "    if i > 0:\n",
    "        ax[2].plot(x_skip,adapt_acc[mask,i], 'v-',color=col[i,:])\n",
    "\n",
    "    ax[i].set_ylim([0,100])\n",
    "\n",
    "ax[0].legend(['LDA','MLP','CNN'])\n",
    "ax[1].legend(['r-LDA','r-MLP','r-CNN'])\n",
    "ax[2].legend(['a-MLP','a-CNN'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96e4d54467b05e62951c9fd7929782b99429e3b62c1a3b146d4f3dbf79f907e6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('adapt_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
