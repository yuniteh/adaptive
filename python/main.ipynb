{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gpu import set_gpu\n",
    "import numpy as np\n",
    "import os\n",
    "import adapt.utils.data_utils as prd\n",
    "import adapt.loop as lp\n",
    "import adapt.ml.lda as dlda\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import adapt.ml.dl_subclass as dl\n",
    "import copy as cp\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time\n",
    "import gc as gc\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "%matplotlib qt\n",
    "mpl.rc('font', size=12)\n",
    "import matplotlib.font_manager\n",
    "plt.rc('font', family='Helvetica')\n",
    "set_gpu()\n",
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count recalibrations\n",
    "path = 'C:/Users/yteh/Documents/work/necal/home data/'\n",
    "subs = os.listdir(path)\n",
    "if 'skip' in subs:\n",
    "    subs = np.delete(subs,subs.index('skip'))\n",
    "bat = 32\n",
    "load_mod = True\n",
    "mod_tot = ['blda','lda','crlda','alda','bcnn','cnn', 'crcnn2','acnn05','acnn30','acewc30','acewc15', 'adcnn30', 'vcnn', 'bvcnn', 'avcnn', 'avcnn1', 'acnnl03','crvcnn','cnn15','crcnn','cnn5','xtra2']\n",
    "ft = 'tdar'\n",
    "iter = 1\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "test_mod = 0\n",
    "thresh = 70\n",
    "aug_w=0\n",
    "aug_scaler=0\n",
    "out_scaler=0\n",
    "save_path = 'C:/Users/yteh/Documents/work/git/projects/adaptive/0404 pre cat_ep 70/'\n",
    "load_path = 'C:/Users/yteh/Documents/work/git/projects/adaptive/0404 pre cat_ep 70/'\n",
    "if not os.path.isdir(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "for it in range(iter):\n",
    "    # first iteration, includes LDA; others exclude LDA\n",
    "    mod_all = ['acnn05','avcnn1','avcnn','cnn','bcnn','crcnn','blda','lda','alda']\n",
    "    mod_all = ['cnn15']\n",
    "    for sub in range(3):\n",
    "        print(subs[sub])\n",
    "        sub_path = path + subs[sub] + '/DATApre/MAT/'\n",
    "        all_files = os.listdir(sub_path)\n",
    "        if 'skip' in all_files:\n",
    "            all_files = np.delete(all_files,all_files.index('skip'))\n",
    "\n",
    "        # load or initialize cnn weights\n",
    "        if load_mod:\n",
    "            with open(load_path + subs[sub] + '_' + str(it) + '_r_accs.p','rb') as f:\n",
    "                all_acc, all_recal, all_val, all_prev, all_train, all_times, all_dof,_, _, c_weights, all_base, all_all, scaler_0, emg_scale, aug_w, aug_scaler,out_scaler= pickle.load(f)\n",
    "        else:\n",
    "            c_weights = None\n",
    "            v_weights = None\n",
    "            v_wc = None\n",
    "            cl_wc = None\n",
    "            scaler_0 = None\n",
    "            all_recal = np.zeros((len(all_files),len(mod_tot)))\n",
    "            all_acc = np.zeros((len(all_files),len(mod_tot)))\n",
    "            all_val = np.zeros((len(all_files),len(mod_tot)))\n",
    "            all_prev = np.zeros((len(all_files),len(mod_tot)))\n",
    "            all_train = np.zeros((len(all_files),len(mod_tot)))\n",
    "            all_times = np.zeros((len(all_files),len(mod_tot)))\n",
    "            all_base = np.zeros((len(all_files),len(mod_tot)))\n",
    "            all_all = np.zeros((len(all_files),len(mod_tot)))\n",
    "            rows, cols = (len(all_files), len(mod_tot))\n",
    "            all_dof = [[0]*cols]*rows\n",
    "\n",
    "        mod_i = 0\n",
    "        for mod in mod_all:\n",
    "            mod_recal = np.zeros((len(all_files),))\n",
    "\n",
    "            if 'lda' in mod:\n",
    "                acc_i = 0\n",
    "            else:\n",
    "                acc_i = 1\n",
    "\n",
    "            cnn = None\n",
    "            ewc = None\n",
    "            clda = None\n",
    "\n",
    "            ep = 30\n",
    "            recal = 0\n",
    "            skip_recal = 0\n",
    "            skip = False\n",
    "            xtra = False\n",
    "            # Loop through files\n",
    "            for i in range(len(all_files)):\n",
    "                # Check if need to recalibrate\n",
    "                if i > 0:\n",
    "                    if all_acc[i,mod_tot.index(mod)] < thresh:\n",
    "                        skip = False\n",
    "                        recal += 1\n",
    "                        print('recal: ' + str(recal) + ' ' + all_files[i])\n",
    "                        all_acc[i,mod_tot.index(mod)] *= -1\n",
    "                        mod_recal[i] = 1\n",
    "                    else:\n",
    "                        skip = True\n",
    "                    \n",
    "                    if 'b' in mod:\n",
    "                        skip = True\n",
    "                        \n",
    "                if not skip:\n",
    "                    # load training file\n",
    "                    train_file = all_files[i]\n",
    "                    train_data, train_params = prd.load_caps_train(sub_path + train_file + '/traindata.mat')\n",
    "\n",
    "                    # if first train, use two train files\n",
    "                    if i == 0:\n",
    "                        # load training file\n",
    "                        train_data, train_params, val_data, val_params = prd.split_data(train_data,train_params,it)\n",
    "                        \n",
    "                        train_file2 = all_files[i+1]\n",
    "                        train_data2, train_params2 = prd.load_caps_train(sub_path + train_file2 + '/traindata.mat')\n",
    "                        \n",
    "                        train_data2, train_params2, val_data2, val_params2 = prd.split_data(train_data2,train_params2,it)\n",
    "\n",
    "                        train_data = np.vstack((train_data,train_data2))\n",
    "                        train_params = np.vstack((train_params,train_params2))\n",
    "                        val_data = np.vstack((val_data,val_data2))\n",
    "                        val_params = np.vstack((val_params,val_params2))\n",
    "\n",
    "                        train_data, train_params, th = prd.threshold(train_data, train_params)\n",
    "                        val_data, val_params, _ = prd.threshold(val_data, val_params,th)\n",
    "\n",
    "                        if mod == 'avcnn1':\n",
    "                            if isinstance(aug_w,list) and load_mod:\n",
    "                                augep = 1\n",
    "                            else:\n",
    "                                augep = 15\n",
    "                                \n",
    "                            t_label,x_clean,x_noise,x_scaled,x_n_scaled,aug_scaler,out_scaler = prd.add_noise_aug(train_data,ft='tdar')\n",
    "                            aug,_ = lp.train_aug(x_scaled,x_n_scaled,t_label,ep=augep,bat=128,print_b=False)\n",
    "                            del t_label,x_clean,x_noise,x_scaled,x_n_scaled\n",
    "                            if augep == 1:\n",
    "                                aug.set_weights(aug_w)\n",
    "                            else:\n",
    "                                aug_w = aug.get_weights()\n",
    "                    else:\n",
    "                        train_data, train_params, _ = prd.threshold(train_data, train_params,th)\n",
    "                        train_data, train_params, val_data, val_params = prd.split_data(train_data,train_params,it)\n",
    "                    \n",
    "                    if i > 0:\n",
    "                        # get previous dofs\n",
    "                        prev_ndof = [n_dof, key, train_dof]\n",
    "                        if mod[0] == 'a' or 'cr' in mod:\n",
    "                            # get current dofs and create key\n",
    "                            train_dof = np.unique(train_params[:,-1])\n",
    "                                    \n",
    "                            key = np.zeros((len(train_dof),))\n",
    "                            # check if current dofs are all in old dof list\n",
    "                            dof_ovlp = np.isin(train_dof,prev_ndof[2],assume_unique=True)\n",
    "                            temp_dof = cp.deepcopy(train_dof)\n",
    "                            # loop through dofs that are in previous dofs, set the keys\n",
    "                            for dof in train_dof[dof_ovlp]:\n",
    "                                key[train_dof==dof] = prev_ndof[1][prev_ndof[2]==dof]\n",
    "                                temp_dof[train_dof==dof] = prev_ndof[2][prev_ndof[2]==dof]\n",
    "\n",
    "                            # check if previous dofs has classes not in this set\n",
    "                            dof_xtra = ~np.isin(prev_ndof[2],temp_dof,assume_unique=True)\n",
    "                            temp_dof = np.hstack((temp_dof,prev_ndof[2][dof_xtra]))\n",
    "                            key = np.hstack((key,prev_ndof[1][dof_xtra]))\n",
    "\n",
    "                            # loop through dofs that are not in previous dofs (ie new classes), add keys\n",
    "                            key_i = 1\n",
    "                            xtra = False\n",
    "                            for dof in train_dof[~dof_ovlp]:\n",
    "                                xtra = True\n",
    "                                key[temp_dof==dof] = np.max(key) + 1\n",
    "\n",
    "                            train_dof = cp.deepcopy(temp_dof)\n",
    "                        else:\n",
    "                            # get current dofs and create key\n",
    "                            train_dof = np.unique(train_params[:,-1])\n",
    "                            key = np.arange(len(train_dof))\n",
    "                    else:\n",
    "                        # get current dofs and create key\n",
    "                        train_dof = np.unique(train_params[:,-1])\n",
    "                        key = np.arange(len(train_dof))\n",
    "\n",
    "                    n_dof = len(train_dof)\n",
    "                    all_dof[i][mod_tot.index(mod)] = train_dof\n",
    "\n",
    "                    train_data, train_params = lp.check_labels(train_data,train_params,train_dof,key,False)\n",
    "\n",
    "                    val_data, val_params = lp.check_labels(val_data,val_params,train_dof,key,False)\n",
    "\n",
    "                    # if combining, save current training data\n",
    "                    if 'cr' in mod:\n",
    "                        # combine old and new training data\n",
    "                        if i > 0:\n",
    "                            train_data = np.vstack((train_data_0[::train_data_0.shape[0]//train_data.shape[0],...],train_data))\n",
    "                            train_params = np.vstack((train_params_0[::train_params_0.shape[0]//train_params.shape[0],...],train_params))\n",
    "\n",
    "                        train_data_0 = cp.deepcopy(train_data)\n",
    "                        train_params_0 = cp.deepcopy(train_params)\n",
    "\n",
    "                    if i == 0:\n",
    "                        all_data = cp.deepcopy(val_data)\n",
    "                        all_params = cp.deepcopy(val_params)\n",
    "                    else:\n",
    "                        prev_params = [all_data,all_params]\n",
    "                        all_data = np.vstack((all_data,val_data))\n",
    "                        all_params = np.vstack((all_params,val_params))\n",
    "                    \n",
    "                    all_data, all_params = lp.check_labels(val_data,val_params,train_dof,key,False)\n",
    "\n",
    "                    noise_b = 'lda' not in mod\n",
    "                    if (mod[0] == 'a' and i > 0) or ('cr' in mod and i > 0) or (mod == 'vcnn' and i > 0):\n",
    "                        _, x_clean_cnn, y_clean, _, x_train_cnn, y_train, x_train_lda, y_train_lda, _, _, _, _ = prd.prep_train_caps(train_data, train_params, emg_scale=emg_scale, scaler=scaler, num_classes=n_dof, prop_b=False, batch_size=bat, ft=ft, noise=noise_b, split=False)\n",
    "                    else:\n",
    "                        _, x_clean_cnn, y_clean, _, x_train_cnn, y_train, x_train_lda, y_train_lda, emg_scale, scaler, _, _ = prd.prep_train_caps(train_data, train_params, prop_b=False, batch_size=bat, ft=ft, noise=noise_b, split=False,num_classes=n_dof)\n",
    "                        if ((i == 0) and (c_weights is not None)) or ((i == 0) and (v_weights is not None)):\n",
    "                            scaler = cp.deepcopy(scaler_0)\n",
    "                    \n",
    "                    _, _, _, _, x_val_cnn, y_val, x_val_lda, y_val_lda, _, _, _, _ = prd.prep_train_caps(val_data, val_params, emg_scale=emg_scale,scaler=scaler, prop_b=False, batch_size=bat, ft=ft, num_classes=n_dof, noise=False, split=False)\n",
    "\n",
    "                    _, _, _, _, all_x, all_y, all_lda, all_lda_y, _, _, _, _ = prd.prep_train_caps(all_data, all_params, emg_scale=emg_scale,scaler=scaler, prop_b=False, batch_size=bat, ft=ft, num_classes=n_dof, noise=False, split=False)\n",
    "\n",
    "                    if i == 0:\n",
    "                        base_x = cp.deepcopy(x_val_cnn)\n",
    "                        base_y = cp.deepcopy(y_val)\n",
    "                        base_lda = cp.deepcopy(x_val_lda)\n",
    "                        base_lda_y = cp.deepcopy(y_val_lda)\n",
    "\n",
    "                        all_x = cp.deepcopy(x_val_cnn)\n",
    "                        all_y = cp.deepcopy(y_val)\n",
    "                        all_lda = cp.deepcopy(x_val_lda)\n",
    "                        all_lda_y = cp.deepcopy(y_val_lda)\n",
    "\n",
    "                    x_clean_scaled = scaler.inverse_transform(x_clean_cnn.reshape(x_clean_cnn.shape[0]*x_clean_cnn.shape[1],-1)).reshape(x_clean_cnn.shape)\n",
    "\n",
    "                    del train_data, train_params, val_data, val_params\n",
    "\n",
    "                    if 'lda' not in mod:\n",
    "                        cnnlda = 'l' in mod\n",
    "                        if i == 0:\n",
    "                            if c_weights is None:\n",
    "                                cnn, all_times[i,mod_tot.index(mod)], w_c, c_c = lp.train_models(traincnn=x_train_cnn,y_train=y_train, mod=['cnn'], n_dof=n_dof, ep=ep, cnnlda=cnnlda, bn_trainable=True,bn_training=True, prog_train=True)\n",
    "                                c_weights = cp.deepcopy([cnn.enc.get_weights(),cnn.clf.get_weights()])\n",
    "                                scaler_0 = cp.deepcopy(scaler)    \n",
    "                            else:\n",
    "                                print('setting CNN weights')\n",
    "                                cnn = dl.CNN(n_class=n_dof)\n",
    "                                cnn(x_train_cnn[:1,...])\n",
    "                                cnn.enc.set_weights(c_weights[0])\n",
    "                                cnn.clf.set_weights(c_weights[1])\n",
    "                                if cnnlda:\n",
    "                                    print('setting LDA weights')\n",
    "                                    w_c = cp.deepcopy(cl_wc[0].astype('float32'))\n",
    "                                    c_c = cp.deepcopy(cl_wc[1].astype('float32'))\n",
    "                            if 'av' in mod:\n",
    "                                mu_class, std_class, N = prd.set_mean(x_clean_scaled,y_clean,key)\n",
    "                            \n",
    "                            if scaler_0 is None:\n",
    "                                scaler_0 = cp.deepcopy(scaler)\n",
    "                            else:\n",
    "                                scaler = cp.deepcopy(scaler_0)\n",
    "\n",
    "                        else:\n",
    "                            prev_w = cnn.get_weights()\n",
    "                            if xtra and mod[0] == 'a':\n",
    "                                print('add neuron')\n",
    "                                cnn = dl.CNN(n_class=n_dof)\n",
    "                                cnn(x_train_cnn[:1,...])\n",
    "                                w_temp = cnn.get_weights()\n",
    "                                w_temp[:-2] = prev_w[:-2]\n",
    "                                w_temp[-2][:,:-1] = prev_w[-2]\n",
    "                                w_temp[-1][:-1] = prev_w[-1]\n",
    "                                cnn.set_weights(w_temp)\n",
    "                            if 'avcnn' in mod:\n",
    "                                prev_mu = [mu_class, std_class, N]\n",
    "                                \n",
    "                                x_gen = np.zeros(x_clean_cnn.shape)\n",
    "                                num_y = x_gen.shape[0]//prev_ndof[0]\n",
    "                                y_gen = np.zeros((x_gen.shape[0],n_dof))\n",
    "                                y_xtra = 0\n",
    "                                x_xtra = 0\n",
    "                                for cl in range(mu_class.shape[0]):#prev_ndof[1].astype(int):\n",
    "                                    x_ind = np.squeeze(y_clean[:,cl]==1)\n",
    "                                    if np.sum(x_ind) > 0:\n",
    "                                        y_gen[x_ind,cl] = 1\n",
    "                                        x_gen[x_ind,...] = np.random.normal(mu_class[cl,...], std_class[cl,...],x_clean_cnn[x_ind,...].shape)\n",
    "                                    else:\n",
    "                                        temp = np.zeros((num_y,n_dof))\n",
    "                                        temp[:,cl] = 1\n",
    "                                        if isinstance(y_xtra,np.ndarray):\n",
    "                                            y_xtra = np.vstack((y_xtra,temp))\n",
    "                                            x_xtra = np.vstack((x_xtra,np.random.normal(mu_class[cl,...], std_class[cl,...],x_clean_cnn[:num_y,...].shape)))\n",
    "                                        else:\n",
    "                                            y_xtra = cp.deepcopy(temp)\n",
    "                                    \n",
    "                                            x_xtra = np.random.normal(mu_class[cl,...], std_class[cl,...],x_clean_cnn[:num_y,...].shape)\n",
    "\n",
    "                                if isinstance(y_xtra,np.ndarray):\n",
    "                                    x_gen = np.vstack((x_gen,x_xtra))\n",
    "                                    y_gen = np.vstack((y_gen,y_xtra))\n",
    "\n",
    "                                x_gen = x_gen[np.sum(y_gen,axis=1)==1,...]\n",
    "                                y_gen = y_gen[np.sum(y_gen,axis=1)==1,...]\n",
    "                                \n",
    "                                if '1' in mod:\n",
    "                                    start_aug = time.time()\n",
    "                                    gen_noise, _, gen_noise_y,_ = prd.aug_gen(x_gen, y_gen, aug, aug_scaler, out_scaler)\n",
    "                                    print('aug: ' + str(time.time() - start_aug))\n",
    "                                else:\n",
    "                                    gen_noise = x_gen\n",
    "                                    gen_noise_y = y_gen\n",
    "                                gen_noise = scaler.transform(gen_noise.reshape(gen_noise.shape[0]*gen_noise.shape[1],-1)).reshape(gen_noise.shape)\n",
    "                                \n",
    "                                x_train_aug = np.vstack((gen_noise,x_train_cnn))\n",
    "                                y_train_aug = np.vstack((gen_noise_y,y_train))\n",
    "\n",
    "\n",
    "                                mu_class, std_class, N = prd.update_mean(x_clean_scaled,y_clean,N,mu_class,std_class,key,prev_ndof[1])\n",
    "                                cnn, all_times[i,mod_tot.index(mod)],_,_ = lp.train_models(traincnn=x_train_aug,y_train=y_train_aug, mod=[cnn], n_dof=n_dof, ep=5, dec=False, lr=0.001, bn_training=False,  prog_train=False)\n",
    "                            elif 'acnn' in mod: # update whole CNN and lda weights\n",
    "                                ep = int(mod[-2:])\n",
    "                                cnn, all_times[i,mod_tot.index(mod)], w_c, c_c = lp.train_models(traincnn=x_train_cnn,y_train=y_train, n_dof=n_dof, ep=ep, mod=[cnn], cnnlda=cnnlda, lr=0.001, bn_training=False,prog_train=False)\n",
    "                            elif 'cr' in mod:\n",
    "                                cnn, all_times[i,mod_tot.index(mod)], w_c, c_c = lp.train_models(traincnn=x_train_cnn,y_train=y_train, mod=[cnn], n_dof=n_dof, ep=5, cnnlda=cnnlda, bn_training=False, prog_train=False)\n",
    "                            elif 'cnn' in mod: # recalibrate cnnlda\n",
    "                                ep = 15\n",
    "                                cnn, all_times[i,mod_tot.index(mod)], w_c, c_c = lp.train_models(traincnn=x_train_cnn,y_train=y_train, mod=['cnn'], n_dof=n_dof, ep=ep, cnnlda=cnnlda, bn_training=True, prog_train=True)\n",
    "                            \n",
    "                        del test_mod\n",
    "                        test_mod = dl.get_test(cnn, test_accuracy)\n",
    "                        if i > 0:\n",
    "                            all_prev[i,mod_tot.index(mod)] = lp.test_models(prev_x, prev_y, None, None, cnn=cnn, clda=clda, test_mod=test_mod, test_accuracy=test_accuracy)[acc_i]\n",
    "                        all_val[i,mod_tot.index(mod)] = lp.test_models(x_val_cnn, y_val, None, None, cnn=cnn, clda=clda, test_mod=test_mod, test_accuracy=test_accuracy)[acc_i]\n",
    "                        all_train[i,mod_tot.index(mod)] = lp.test_models(x_clean_cnn, y_clean, None, None, cnn=cnn, clda=clda, test_mod=test_mod, test_accuracy=test_accuracy)[acc_i]\n",
    "                        all_base[i,mod_tot.index(mod)] = lp.test_models(base_x, base_y, None, None, cnn=cnn, clda=clda, test_mod=test_mod, test_accuracy=test_accuracy)[acc_i]\n",
    "                        all_all[i,mod_tot.index(mod)] = lp.test_models(all_x, all_y, None, None, cnn=cnn, clda=clda, test_mod=test_mod, test_accuracy=test_accuracy)[acc_i]\n",
    "                        \n",
    "                        if all_val[i,mod_tot.index(mod)] < thresh:\n",
    "                            mod_recal[i] = -1\n",
    "                            print('bad recal')\n",
    "                            if i > 0:\n",
    "                                n_dof, key, train_dof = prev_ndof\n",
    "                                if 'vcnn' in mod:\n",
    "                                    mu_class, std_class, N = prev_mu\n",
    "                                cnn = dl.CNN(n_class = n_dof)\n",
    "                                cnn(x_train_cnn[:1,...])\n",
    "                                cnn.set_weights(prev_w)\n",
    "                                del test_mod\n",
    "                                test_mod = dl.get_test(cnn, test_accuracy)\n",
    "                                all_data, all_params = prev_params\n",
    "                            else:\n",
    "                                print('keeping new model')\n",
    "                                mod_recal[i] = -2\n",
    "                        elif 'cr' in mod:\n",
    "                            clean_data_0 = cp.deepcopy(x_clean_cnn)\n",
    "                            clean_params_0 = cp.deepcopy(y_clean)\n",
    "                    else:\n",
    "                        if i == 0:\n",
    "                            N = np.zeros((n_dof),)\n",
    "                            cov_class = np.zeros([x_train_lda.shape[1],x_train_lda.shape[1]])\n",
    "                            mu_class = np.zeros([n_dof,x_train_lda.shape[1]])\n",
    "                        prev_lda = [mu_class,cov_class,N]\n",
    "                        start_time = time.time()\n",
    "                        if mod[0] != 'a' or (i == 0 and mod[0] == 'a'):\n",
    "                            w, c, mu_class, _, _, N, cov_class = dlda.train_lda(x_train_lda, y_train_lda, key)\n",
    "                        else:\n",
    "                            w, c, mu_class, cov_class, N = dlda.update_lda(x_train_lda, y_train_lda, N, mu_class, cov_class, key, prev_ndof[1])\n",
    "                        all_times[i,mod_tot.index(mod)] = time.time() - start_time\n",
    "\n",
    "                        all_val[i,mod_tot.index(mod)] = lp.test_models(None, None, x_val_lda, y_val_lda, lda=[w,c])[acc_i]\n",
    "                        all_train[i,mod_tot.index(mod)] = lp.test_models(None, None, x_train_lda, y_train_lda, lda=[w,c])[acc_i]\n",
    "                        all_base[i,mod_tot.index(mod)] = lp.test_models(None, None, base_lda, base_lda_y, lda=[w,c])[acc_i]\n",
    "                        all_all[i,mod_tot.index(mod)] = lp.test_models(None, None, all_lda, all_lda_y, lda=[w,c])[acc_i]\n",
    "                        if i > 0:\n",
    "                            all_prev[i,mod_tot.index(mod)] = lp.test_models(None, None, prev_x_lda, prev_y_lda, lda=[w,c])[acc_i]\n",
    "                        if all_val[i,mod_tot.index(mod)] < thresh:\n",
    "                            mod_recal[i] = -1\n",
    "                            print('bad recal')\n",
    "                            if i > 0:\n",
    "                                mu_class, cov_class, N = prev_lda\n",
    "                                n_dof, key, train_dof = prev_ndof\n",
    "                                all_data, all_params = prev_params\n",
    "                            else:\n",
    "                                print('keeping new model')\n",
    "                                mod_recal[i] = -2\n",
    "                        del x_train_lda, y_train_lda\n",
    "                    \n",
    "                    if mod_recal[i] != -1 or i == 0 :\n",
    "                        prev_x = cp.deepcopy(x_val_cnn)\n",
    "                        prev_y = cp.deepcopy(y_val)\n",
    "                        prev_x_lda = cp.deepcopy(x_val_lda)\n",
    "                        prev_y_lda = cp.deepcopy(y_val_lda)\n",
    "                    \n",
    "                    del  x_val_cnn, y_val, x_val_lda, y_val_lda, x_clean_cnn, y_clean,x_train_cnn, y_train\n",
    "                \n",
    "                if i < len(all_files)-1:\n",
    "                    # load data\n",
    "                    test_file = all_files[i+1]\n",
    "\n",
    "                    test_data, test_params = prd.load_caps_train(sub_path + test_file + '/traindata.mat')\n",
    "                    \n",
    "                    # check class labels\n",
    "                    test_data, test_params, _ = prd.threshold(test_data, test_params, th)\n",
    "                    test_data, test_params = lp.check_labels(test_data,test_params,train_dof,key,True)\n",
    "\n",
    "                    # test \n",
    "                    y_test, _, x_test_cnn, x_test_lda, y_test_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=n_dof, ft=ft, split=False)\n",
    "                    \n",
    "                    # test \n",
    "                    if 'lda' in mod:\n",
    "                        all_acc[i+1,mod_tot.index(mod)] = lp.test_models(None, None,  x_test_lda, y_test_lda, lda=[w,c])[acc_i]\n",
    "                    else:\n",
    "                        all_acc[i+1,mod_tot.index(mod)] = lp.test_models(x_test_cnn, y_test, x_test_lda, y_test_lda, cnn=cnn, clda=clda, test_mod=test_mod, test_accuracy=test_accuracy)[acc_i]\n",
    "\n",
    "                    print ('Set: ' + train_file + ', Test: ' + test_file + ',', f'Accuracy: {all_acc[i+1,mod_tot.index(mod)]:.2f}', f', Val: {all_val[i,mod_tot.index(mod)]:.2f}', f', Prev: {all_prev[i,mod_tot.index(mod)]:.2f}', f', Base: {all_base[i,mod_tot.index(mod)]:.2f}')\n",
    "                    del y_test, x_test_cnn, x_test_lda, y_test_lda, test_data, test_params\n",
    "\n",
    "            all_recal[:,mod_tot.index(mod)] = mod_recal\n",
    "\n",
    "            print('------------------------' + mod + ' ' + str(np.sum(mod_recal==1)) + ' - ' + str(np.sum(mod_recal==-1)) + ' -- ' + str(np.sum(mod_recal==-2)) + '----------------------')\n",
    "            mod_i += 1\n",
    "\n",
    "            if 'cr' in mod:\n",
    "            \n",
    "                del train_data_0, train_params_0\n",
    "\n",
    "        with open(save_path + subs[sub] + '_' + str(it) + '_r_accs.p','wb') as f:\n",
    "            pickle.dump([all_acc, all_recal, all_val, all_prev, all_train, all_times, all_dof, mod_all, mod_tot, c_weights, all_base, all_all, scaler_0, emg_scale, aug_w, aug_scaler, out_scaler],f)\n",
    "\n",
    "        gc.collect(generation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# st = time.time()\n",
    "%timeit test = np.random.normal(3,2,(200,8,10))\n",
    "# print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit prd.update_mean(x_clean_scaled,y_clean,N,mu_class,std_class,key,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen = np.zeros(x_clean_cnn.shape)\n",
    "num_y = x_gen.shape[0]//prev_ndof[0]\n",
    "y_gen = np.zeros((x_gen.shape[0],n_dof))\n",
    "y_xtra = 0\n",
    "x_xtra = 0\n",
    "for cl in range(mu_class.shape[0]):#prev_ndof[1].astype(int):\n",
    "    x_ind = np.squeeze(y_clean[:,cl]==1)\n",
    "    if np.sum(x_ind) > 0:\n",
    "        y_gen[x_ind,cl] = 1\n",
    "        x_gen[x_ind,...] = np.random.normal(mu_class[cl,...], std_class[cl,...],x_clean_cnn[x_ind,...].shape)\n",
    "    else:\n",
    "        temp = np.zeros((num_y,n_dof))\n",
    "        temp[:,cl] = 1\n",
    "        if isinstance(y_xtra,np.ndarray):\n",
    "            y_xtra = np.vstack((y_xtra,temp))\n",
    "            x_xtra = np.vstack((x_xtra,np.random.normal(mu_class[cl,...], std_class[cl,...],x_clean_cnn[:num_y,...].shape)))\n",
    "        else:\n",
    "            y_xtra = cp.deepcopy(temp)\n",
    "    \n",
    "            x_xtra = np.random.normal(mu_class[cl,...], std_class[cl,...],x_clean_cnn[:num_y,...].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s = scaler.inverse_transform(x_noise_0.reshape(x_noise_0.shape[0]*x_noise_0.shape[1],-1)).reshape(x_noise_0.shape)\n",
    "\n",
    "ind = y_train_0[:,2] ==1\n",
    "print(np.sum(ind))\n",
    "fig,ax = plt.subplots(8,1,figsize=(15,10))\n",
    "for i in range(8):\n",
    "    ax[i].plot(np.squeeze(x_s[ind,i,...][:500,...]).T)\n",
    "    ax[i].plot(np.squeeze(mu_class[0,i,...]).T)\n",
    "    ax[i].set_ylim([-3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s = scaler.inverse_transform(x_clean_0.reshape(x_clean_0.shape[0]*x_clean_0.shape[1],-1)).reshape(x_clean_0.shape)\n",
    "\n",
    "ind = y_clean_0[:,1] ==1\n",
    "print(np.sum(ind))\n",
    "fig,ax = plt.subplots(8,1,figsize=(15,10))\n",
    "for i in range(8):\n",
    "    ax[i].plot(np.squeeze(x_s[ind,i,...]).T)\n",
    "    ax[i].plot(np.squeeze(mu_class[0,i,...]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = y_gen[:,0] ==1\n",
    "print(np.sum(ind))\n",
    "fig,ax = plt.subplots(8,1,figsize=(15,10))\n",
    "for i in range(8):\n",
    "    ax[i].plot(np.squeeze(x_gen[ind,i,...]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = gen_noise_y[:,2] ==1\n",
    "x_s = scaler.inverse_transform(gen_noise.reshape(gen_noise.shape[0]*gen_noise.shape[1],-1)).reshape(gen_noise.shape)\n",
    "\n",
    "fig,ax = plt.subplots(8,1,figsize=(15,10))\n",
    "for i in range(8):\n",
    "    ax[i].plot(np.squeeze(x_s[ind,i,...]).T)\n",
    "    ax[i].set_ylim([-3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = gen_noise_y[:,1]==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(8,1,figsize=(15,10))\n",
    "for i in range(8):\n",
    "    ax[i].plot(np.squeeze(gen_noise[ind,i,...][-50:,...]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(subs[sub] + '_' + str(it) + '_r_accs.p','wb') as f:\n",
    "    pickle.dump([all_acc, all_recal, all_val, all_prev, all_train, all_times, all_dof, mod_all, mod_tot, c_weights, v_weights, cl_wc, scaler_0, emg_scale, aug.get_weights(), aug_scaler],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count recalibrations\n",
    "path = 'C:/Users/yteh/Documents/work/necal/home data/'\n",
    "subs = os.listdir(path)\n",
    "if 'skip' in subs:\n",
    "    subs = np.delete(subs,subs.index('skip'))\n",
    "ft = 'tdar'\n",
    "\n",
    "for sub in range(4,5):\n",
    "    print(subs[sub])\n",
    "    sub_path = path + subs[sub] + '/DATApre/MAT/'\n",
    "    all_files = os.listdir(sub_path)\n",
    "    if 'skip' in all_files:\n",
    "        all_files = np.delete(all_files,all_files.index('skip'))\n",
    "\n",
    "    train_file = all_files[0]\n",
    "    train_data, train_params = prd.load_caps_train(sub_path + train_file + '/traindata.mat')\n",
    "    t_label,x_clean,x_noise,x_scaled,x_n_scaled,scaler = prd.add_noise_aug(train_data,ft='tdar')\n",
    "\n",
    "    out = lp.train_aug(x_scaled,x_n_scaled,t_label,ep=30,bat=128,print_b=False)\n",
    "    aug = out[0]\n",
    "    gc.collect(generation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_clean_cnn, y_clean, _, x_train_cnn, y_train, x_train_lda, y_train_lda, _, _, _, _ = prd.prep_train_caps(train_data, train_params, emg_scale=emg_scale, scaler=scaler, num_classes=n_dof, prop_b=False, batch_size=bat, ft=ft, noise=noise_b, split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy,clean,y=aug_gen(raw, params, mod, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = out[0]\n",
    "typ = .3\n",
    "test = mod(x_scaled[t_label==typ,...],t_label[t_label==typ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test.shape[0]):\n",
    "    plt.plot(test[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gpu import set_gpu\n",
    "import numpy as np\n",
    "import os\n",
    "import adapt.utils.data_utils as prd\n",
    "import adapt.loop as lp\n",
    "import adapt.ml.lda as dlda\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import adapt.ml.dl_subclass as dl\n",
    "import copy as cp\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time\n",
    "import gc as gc\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "%matplotlib qt\n",
    "mpl.rc('font', size=12)\n",
    "import matplotlib.font_manager\n",
    "plt.rc('font', family='Helvetica')\n",
    "set_gpu()\n",
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count recalibrations\n",
    "path = 'C:/Users/yteh/Documents/work/necal/home data/'\n",
    "subs = os.listdir(path)\n",
    "if 'skip' in subs:\n",
    "    subs = np.delete(subs,subs.index('skip'))\n",
    "bat = 32\n",
    "ft = 'tdar'\n",
    "iter = 1\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "plot_mod = ['lda','alda','cnn','acnn03','avcnn','crcnn']\n",
    "plot_mod = ['lda','alda','cnn','acnn05','avcnn']\n",
    "plot_mod = ['cnn','cnn5','cnn15']\n",
    "\n",
    "bar_c = np.array(sns.color_palette(\"Paired\"))*.8\n",
    "\n",
    "plot_path = 'C:/Users/yteh/Documents/work/git/projects/adaptive/0404 pre cat 70/'\n",
    "plot_path2 = 'C:/Users/yteh/Documents/work/git/projects/adaptive/0404 post cat 70/'\n",
    "plot_path2 = 'C:/Users/yteh/Documents/work/git/projects/adaptive/0404 pre cat_ep 70/'\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\",category=RuntimeWarning)\n",
    "    for plot_i in range(1,2):\n",
    "        fig, ax = plt.subplots(7,1,figsize=(7,14))\n",
    "        \n",
    "        fig1, bar_ax = plt.subplots(1,7,figsize=(12,3))\n",
    "        sub_i=0\n",
    "        sub_j=0\n",
    "        rec_prc = np.zeros((7,22))\n",
    "        fl_prc = np.zeros((7,22))\n",
    "        sub_base = np.zeros((7,22))\n",
    "        sub_all = np.zeros((7,22))\n",
    "        sub_new = np.zeros((7,22))\n",
    "        sub_base2 = np.zeros((7,22))\n",
    "        sub_all2 = np.zeros((7,22))\n",
    "        sum_acc = np.zeros((7,22))\n",
    "        sum_std = np.zeros((7,22))\n",
    "        sub_time = np.zeros((7,22))\n",
    "        sub_stdt = np.zeros((7,22))\n",
    "        sub_init = np.zeros((7,22))\n",
    "        tot_recal = []\n",
    "        tot_fail = []\n",
    "        fig_bx, ax_bx = plt.subplots(7,1,figsize=(4,14))\n",
    "        for sub in range(7):    \n",
    "            # fig, ax = plt.subplots(figsize=(7,2))\n",
    "            it_acc = []\n",
    "            it_recal = []\n",
    "            it_fail = []\n",
    "            it_val = []\n",
    "            it_prev = []\n",
    "            it_train = []\n",
    "            it_times = []\n",
    "            it_replaced = []\n",
    "            it_base = []\n",
    "            it_all= []\n",
    "            for it in range(iter):#iter):\n",
    "                \n",
    "                # load or initialize cnn weights\n",
    "                if plot_i == 1:\n",
    "                    with open(plot_path2 +subs[sub] + '_' + str(it) + '_r_accs.p','rb') as f:\n",
    "                        all_acc, all_recal, all_val, all_prev, all_train, all_times, all_dof, _, mod_tot, _,all_base, all_all,  scaler_0, emg_scale,_,_,_ = pickle.load(f)\n",
    "                elif plot_i == 0:\n",
    "                    with open(plot_path +subs[sub] + '_' + str(it) + '_r_accs.p','rb') as f:\n",
    "                        all_acc, all_recal, all_val, all_prev, all_train, all_times, all_dof, _, mod_tot, _,all_base, all_all,  scaler_0, emg_scale,_,_,_= pickle.load(f)\n",
    "                else:\n",
    "                    with open(plot_path2 +subs[sub] + '_' + str(it) + '_r_accs.p','rb') as f:\n",
    "                        all_acc, all_recal, all_val, all_prev, all_train, all_times, all_dof, _, mod_tot, _,all_base, all_all,  scaler_0, emg_scale,_,_,_ = pickle.load(f)\n",
    "\n",
    "                    comb_acc = cp.deepcopy(all_acc)\n",
    "                    comb_recal = cp.deepcopy(all_recal)\n",
    "                    comb_val = cp.deepcopy(all_val)\n",
    "                    comb_prev = cp.deepcopy(all_prev)\n",
    "                    comb_train = cp.deepcopy(all_train)\n",
    "                    comb_times = cp.deepcopy(all_times)\n",
    "                    comb_base = cp.deepcopy(all_base)\n",
    "                    comb_all = cp.deepcopy(all_all)\n",
    "\n",
    "                    with open(plot_path +subs[sub] + '_' + str(it) + '_r_accs.p','rb') as f:\n",
    "                        all_acc, all_recal, all_val, all_prev, all_train, all_times, all_dof, _, mod_tot,_, all_base, all_all, scaler_0, emg_scale,_,_,_= pickle.load(f)\n",
    "                    \n",
    "                    pre_num = all_acc.shape[0]\n",
    "        \n",
    "                    all_acc = np.vstack((all_acc,comb_acc))\n",
    "                    all_recal = np.vstack((all_recal,comb_recal))\n",
    "                    all_val = np.vstack((all_val,comb_val))\n",
    "                    all_prev = np.vstack((all_prev,comb_prev))\n",
    "                    all_train = np.vstack((all_train,comb_train))\n",
    "                    all_times = np.vstack((all_times,comb_times))\n",
    "                    all_base = np.vstack((all_base,comb_base))\n",
    "                    all_all = np.vstack((all_all,comb_all))\n",
    "\n",
    "                lda_ind = mod_tot.index('alda') + 1\n",
    "                all_acc[all_acc==0] = np.nan\n",
    "                all_val[all_val==0] = np.nan\n",
    "                all_prev[all_prev==0] = np.nan\n",
    "                all_train[all_train==0] = np.nan\n",
    "                all_times[all_times==0] = np.nan\n",
    "                # all_base[all_base==0] = np.nan\n",
    "                # all_all[all_all==0] = np.nan\n",
    "\n",
    "                it_acc.append(all_acc)\n",
    "                it_recal.append(np.sum(all_recal==1,axis=0))\n",
    "                it_fail.append(np.sum(all_recal==-1,axis=0))\n",
    "                it_replaced.append(np.sum(all_recal==-2,axis=0))\n",
    "                it_val.append(all_val)\n",
    "                it_prev.append(all_prev)\n",
    "                it_train.append(all_train)\n",
    "                it_times.append(all_times)\n",
    "                it_base.append(all_base)\n",
    "                it_all.append(all_all)\n",
    "\n",
    "                tot_recal.append(100*np.sum(all_recal==1,axis=0)/all_acc.shape[0])\n",
    "                tot_fail.append(100*np.sum(all_recal==-1,axis=0)/all_acc.shape[0])\n",
    "\n",
    "            it_acc2 = cp.deepcopy(it_acc)\n",
    "            for i in range(len(it_acc2)):\n",
    "                x = it_val[i] < 0\n",
    "                it_acc2[i][(it_acc[i]< 0) & (it_val[i] > 70)]= it_val[i][(it_acc[i]< 0)& (it_val[i] > 70)]\n",
    "\n",
    "            it_acc = np.array(it_acc)\n",
    "            it_recal =np.array(it_recal)\n",
    "            it_fail = np.array(it_fail)\n",
    "            it_replaced = np.array(it_replaced)\n",
    "            it_val=np.array(it_val)\n",
    "            it_prev=np.array(it_prev)\n",
    "            it_train=np.array(it_train)\n",
    "            it_times=np.array(it_times)\n",
    "            # it_base=np.array(it_base)\n",
    "            # it_all=np.array(it_all)\n",
    "\n",
    "            \n",
    "\n",
    "            # sub_base1 = np.nanmean(np.nanmean(it_base[:,1:pre_num,:]/it_val[:,[0],:],axis=1),axis=0)\n",
    "            # sub_all1 = np.nanmean(np.nanmean(it_all[:,1:pre_num,:]/it_val[:,[0],:],axis=1),axis=0)\n",
    "            # sub_new[sub,:] = np.nanmean(np.nanmean(it_val[:,1:,:],axis=1),axis=0)\n",
    "            # sub_base2 = np.nanmean(np.nanmean(it_base[:,pre_num+1:,:]/it_val[:,[pre_num],:],axis=1),axis=0)\n",
    "            # sub_all2 = np.nanmean(np.nanmean(it_all[:,pre_num+1:,:]/it_val[:,[pre_num],:],axis=1),axis=0)\n",
    "            # # print(np.stack((sub_base,sub_base2)).shape)\n",
    "            # sub_base[sub,:] = np.nanmean(np.stack((sub_base1,sub_base2)),axis=0)\n",
    "            # sub_all[sub,:] = np.nanmean(np.stack((sub_all1,sub_all2)),axis=0)\n",
    "\n",
    "\n",
    "            ave_acc2 = np.nanmean(np.abs(it_acc2),axis=0)\n",
    "            ave_acc = np.nanmean(np.abs(it_acc),axis=0)\n",
    "            ave_val = np.nanmean(np.abs(it_val),axis=0)\n",
    "            ave_prev = np.nanmean(np.abs(it_prev),axis=0)\n",
    "            ave_train = np.nanmean(np.abs(it_train),axis=0)\n",
    "            msk = np.ones((it_times.shape[1],))\n",
    "            msk[0] = 0\n",
    "            # msk[pre_num] = 0\n",
    "            ave_times = np.nanmean(it_times[:,msk.astype(bool),:],axis=1)\n",
    "            ave_times = np.nanmean(ave_times,axis=0)\n",
    "            ave_init = np.nanmean(np.abs(it_times[:,~msk.astype(bool),:]),axis=1)\n",
    "            ave_init = np.nanmean(ave_init,axis=0)\n",
    "            ave_recal = np.nanmean(it_recal,axis=0)\n",
    "            ave_fail = np.nanmean(it_fail,axis=0)\n",
    "            ave_replaced = np.nanmean(it_replaced,axis=0)\n",
    "            \n",
    "            sub_init[sub,:] = ave_init\n",
    "            sub_time[sub,:] = ave_times\n",
    "            # sub_stdt[sub,:] = np.nanstd(ave_times,axis=0)\n",
    "\n",
    "            std_acc2 = np.nanstd(np.abs(it_acc2),axis=0)/np.sum(~np.isnan(it_acc2),axis=0)\n",
    "            std_acc = np.nanstd(np.abs(it_acc),axis=0)/np.sum(~np.isnan(it_acc),axis=0)\n",
    "            std_val = np.nanstd(np.abs(it_val),axis=0)/np.sum(~np.isnan(it_val),axis=0)\n",
    "            std_prev = np.nanstd(np.abs(it_prev),axis=0)/np.sum(~np.isnan(it_prev),axis=0)\n",
    "            std_train = np.nanstd(np.abs(it_train),axis=0)/np.sum(~np.isnan(it_train),axis=0)\n",
    "            std_times = np.nanstd(np.abs(it_times),axis=0)/np.sum(~np.isnan(it_times),axis=0)\n",
    "            std_recal = np.nanstd(it_recal,axis=0)/np.sum(~np.isnan(it_recal),axis=0)\n",
    "            std_fail = np.nanstd(it_fail,axis=0)/np.sum(~np.isnan(it_fail),axis=0)\n",
    "            std_replaced = np.nanstd(it_replaced,axis=0)/np.sum(~np.isnan(it_replaced),axis=0)\n",
    "\n",
    "            acc_sum = np.nanmean(ave_acc2,axis=0)\n",
    "            rng = np.nanmax(ave_acc2,axis=0) - np.nanmin(ave_acc2,axis=0)\n",
    "            acc_std = np.nanstd(ave_acc2,axis=0)\n",
    "\n",
    "            rec_prc[sub,:] = 100*ave_recal/all_acc.shape[0]\n",
    "            fl_prc[sub,:] = 100*ave_fail/all_acc.shape[0]\n",
    "            # ave_rc[sub,:] = rec_prc[mod_tot.index(plot_mod)]\n",
    "            # ave_fl[sub,:] = fl_prc[mod_tot.index(plot_mod)]\n",
    "\n",
    "            width = .1\n",
    "            p_x = 0\n",
    "            c_x = 0\n",
    "            x = np.arange(len(plot_mod))\n",
    "            for mod in plot_mod:\n",
    "                plot_ind = mod_tot.index(mod)\n",
    "                # ax.plot(ave_acc[2:,plot_ind],'.-',label= mod + ' = '+ str(ave_recal[plot_ind,0]) + ' +/- ' + str(std_recal[plot_ind,0]))\n",
    "                x = ~np.isnan(ave_val[:,plot_ind]) \n",
    "                # ave_acc2 = cp.deepcopy(ave_acc)\n",
    "                # ave_acc[x,plot_ind] = ave_val[x,plot_ind]\n",
    "\n",
    "                # ax[sub,0].plot(ave_acc[:,plot_ind],'.-',ms=8,label= mod)# + ' = '+ \"{:.2f}\".format(ave_recal[plot_ind]) + ' +/- ' + \"{:.2f}\".format(std_recal[plot_ind]) + ', ' + \"{:.2f}\".format(ave_fail[plot_ind]) +' failed'+ ', ' + \"{:.2f}\".format(ave_replaced[plot_ind]) +' replaced')#str(std_recal[plot_ind,0]))\n",
    "                # ax.plot(np.squeeze(np.where(x)),ave_acc2[x,plot_ind],'kx',ms=12)\n",
    "                # ax.plot(ave_acc2[:,plot_ind],'-',ms=8,label= mod)# + ' = '+ \"{:.2f}\".format(ave_recal[plot_ind]) + ' +/- ' + \"{:.2f}\".format(std_recal[plot_ind])+ ', ' + \"{:.2f}\".format(ave_fail[plot_ind]) + ' failed'+ ', ' + \"{:.2f}\".format(ave_replaced[plot_ind]) +' replaced')#+ str(std_recal[plot_ind,0]))\n",
    "                # ax.plot(np.squeeze(np.where(x)), ave_val[~np.isnan(ave_val[:,plot_ind]),plot_ind],'.-',ms=8,label= mod + ' = '+ str(ave_recal[plot_ind,0]) + ' +/- ' + str(std_recal[plot_ind,0]))\n",
    "                # ave_acc = ave_acc[~np.isnan(ave_acc)]\n",
    "                # ax[sub].plot(ave_acc[~np.isnan(ave_acc[:,plot_ind]),plot_ind],'-',ms=8,label= mod)\n",
    "                # ax[sub].fill_between(np.arange(ave_acc[~np.isnan(ave_acc[:,plot_ind]),plot_ind].shape[0]),ave_acc[~np.isnan(ave_acc[:,plot_ind]),plot_ind]-std_acc[~np.isnan(ave_acc[:,plot_ind]),plot_ind],ave_acc[~np.isnan(ave_acc[:,plot_ind]),plot_ind]+std_acc[~np.isnan(ave_acc[:,plot_ind]),plot_ind],alpha=.3)\n",
    "\n",
    "                ax[sub].plot(ave_acc2[~np.isnan(ave_acc2[:,plot_ind]),plot_ind],'-',ms=8,label= mod)\n",
    "                ax[sub].fill_between(np.arange(ave_acc2[~np.isnan(ave_acc2[:,plot_ind]),plot_ind].shape[0]),ave_acc2[~np.isnan(ave_acc2[:,plot_ind]),plot_ind]-std_acc2[~np.isnan(ave_acc2[:,plot_ind]),plot_ind],ave_acc2[~np.isnan(ave_acc2[:,plot_ind]),plot_ind]+std_acc2[~np.isnan(ave_acc2[:,plot_ind]),plot_ind],alpha=.3)\n",
    "\n",
    "                # print(plot_ind)\n",
    "                # print(np.nanmean(ave_acc[~np.isnan(ave_acc[:,plot_ind]),plot_ind], axis=0))\n",
    "                # print(np.nanstd(ave_acc[~np.isnan(ave_acc[:,plot_ind]),plot_ind], axis=0))\n",
    "                # print(np.nanmax(ave_acc[~np.isnan(ave_acc[:,plot_ind]),plot_ind], axis=0) - np.nanmin(ave_acc[~np.isnan(ave_acc[:,plot_ind]),plot_ind], axis=0))\n",
    "                # sum_acc[sub,plot_ind] = np.nanmean(ave_acc2[:,plot_ind]) \n",
    "                # sum_std[sub,plot_ind] = np.nanstd(ave_acc2[:,plot_ind])\n",
    "\n",
    "                # ax[sub].plot(ave_acc2[:,plot_ind],'-',ms=8,label= mod)\n",
    "                # ax[sub].fill_between(np.arange(ave_acc2[~np.isnan(ave_acc2[:,plot_ind]),plot_ind].shape[0]),ave_acc2[~np.isnan(ave_acc2[:,plot_ind]),plot_ind]-std_acc2[~np.isnan(ave_acc2[:,plot_ind]),plot_ind],ave_acc2[~np.isnan(ave_acc2[:,plot_ind]),plot_ind]+std_acc2[~np.isnan(ave_acc2[:,plot_ind]),plot_ind],alpha=.3)\n",
    "\n",
    "                # if sub == 3:\n",
    "                #     ax[sub_i,:].plot(ave_acc2[:,plot_ind],'-',ms=8,label= mod)\n",
    "                #     ax[sub_i,:].fill_between(np.arange(ave_acc2[:,plot_ind].shape[0]),ave_acc2[:,plot_ind]-std_acc2[:,plot_ind],ave_acc2[:,plot_ind]+std_acc2[:,plot_ind],alpha=.3)\n",
    "                # bar_ax[sub].bar(p_x*width, sum_acc[sub,plot_ind], width*.9, color=bar_c[c_x+1], yerr=sum_std[sub,plot_ind])\n",
    "                # bar_ax[sub].set_xticks([])\n",
    "                # bar_ax[sub].set_ylim([0,100])\n",
    "                # if sub > 0:\n",
    "                #     bar_ax[sub].set_yticklabels([])\n",
    "                # else:\n",
    "                #     bar_ax[sub].set_ylabel('Recalibration Frequency (%)')\n",
    "\n",
    "                bar_ax[sub].bar(p_x*width, rec_prc[sub,plot_ind], width*.9, label='Successful',color=bar_c[c_x+1], yerr=100*std_recal[plot_ind]/all_acc.shape[0])\n",
    "                bar_ax[sub].bar(p_x*width, fl_prc[sub,plot_ind], width*.9, bottom=100*ave_recal[plot_ind]/all_acc.shape[0],label='Failed',color=bar_c[c_x], yerr=100*std_fail[plot_ind]/all_acc.shape[0])\n",
    "                bar_ax[sub].set_xticks([])\n",
    "                bar_ax[sub].set_ylim([0,100])\n",
    "                if sub > 0:\n",
    "                    bar_ax[sub].set_yticklabels([])\n",
    "                else:\n",
    "                    bar_ax[sub].set_ylabel('Recalibration Frequency (%)')\n",
    "\n",
    "                # bar_ax[sub].bar(p_x*width, rng[plot_ind], width*.9,color=bar_c[c_x+1])\n",
    "                # bar_ax[sub].bar(p_x*width, acc_sum[plot_ind], width*.9,color=bar_c[c_x+1], yerr=acc_std[plot_ind])\n",
    "                bar_ax[sub].set_xticks([])\n",
    "                bar_ax[sub].set_ylim([0,100])\n",
    "                if sub > 0:\n",
    "                    bar_ax[sub].set_yticklabels([])\n",
    "                else:\n",
    "                    bar_ax[sub].set_ylabel('Average Accuracy (%)')\n",
    "\n",
    "                p_x += 1\n",
    "                c_x +=2\n",
    "            # ax.legend()\n",
    "            # ax[sub].set_xticks([])\n",
    "            # for i in range(2):\n",
    "            # ax[:].axhline(70, ls='--', color='grey')\n",
    "                ax[sub].axhline(70,ls='--',color='grey')\n",
    "                ax[sub].set_ylim([0,100])\n",
    "                ax[sub].set_xlim([0, np.sum(~np.isnan(ave_acc2[:,plot_ind]))-1])\n",
    "                ax[sub].set_xticks([])\n",
    "\n",
    "            bx_ms = np.zeros((ave_acc2.shape[1]))\n",
    "            bx_ms[0] = 1\n",
    "            bx_ms[4] = 1\n",
    "            temp = ave_acc2[:,bx_ms.astype(bool)]\n",
    "            temp = temp[~np.isnan(ave_acc2[:,0]),:]\n",
    "            ax_bx[sub].boxplot(temp,sym=\"\")\n",
    "            ax_bx[sub].set_ylim([0,100])\n",
    "            if sub%2 ==0:\n",
    "                sub_j+=1\n",
    "            else:\n",
    "                sub_j-=1\n",
    "                sub_i+=1\n",
    "\n",
    "        fig2,bar_a = plt.subplots()\n",
    "        p_x=0\n",
    "        for mod in plot_mod:\n",
    "            bar_a.bar(p_x*width, np.nanmean(rec_prc,axis=0)[mod_tot.index(mod)], width*.9, label='Successful',color=bar_c[c_x+1], yerr=np.nanstd(rec_prc,axis=0)[mod_tot.index(mod)]/7)\n",
    "            bar_a.bar(p_x*width, np.nanmean(fl_prc,axis=0)[mod_tot.index(mod)], width*.9, bottom= np.nanmean(rec_prc,axis=0)[mod_tot.index(mod)],label='Failed',color=bar_c[c_x], yerr=np.nanstd(fl_prc,axis=0)[mod_tot.index(mod)]/7)\n",
    "            p_x+=1\n",
    "        bar_a.set_xticks([])\n",
    "        bar_a.set_ylim([0,100])\n",
    "        bar_a.set_ylabel('Recalibration Frequency (%)')\n",
    "        \n",
    "\n",
    "        # fig2,bar_a = plt.subplots(1,3,figsize=(10,3))\n",
    "        # p_x=0\n",
    "        # for mod in plot_mod:\n",
    "        #     bar_a[0].bar(p_x*width, 100*np.nanmean(sub_base,axis=0)[mod_tot.index(mod)], width*.9, color=bar_c[c_x+1], yerr=100*np.nanstd(sub_base,axis=0)[mod_tot.index(mod)]/7)\n",
    "        #     bar_a[1].bar(p_x*width, 100*np.nanmean(sub_all,axis=0)[mod_tot.index(mod)], width*.9, color=bar_c[c_x+1], yerr=100*np.nanstd(sub_all,axis=0)[mod_tot.index(mod)]/7)\n",
    "        #     bar_a[2].bar(p_x*width, np.nanmean(sub_new,axis=0)[mod_tot.index(mod)], width*.9, color=bar_c[c_x+1], yerr=np.nanstd(sub_new,axis=0)[mod_tot.index(mod)]/7)\n",
    "        #     p_x+=1\n",
    "        # for bar_i in range(3):\n",
    "        #     bar_a[bar_i].set_xticks([])\n",
    "        #     bar_a[bar_i].set_ylim([0,100])\n",
    "        # bar_a[0].set_ylabel('%')\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig1.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = np.array(tot_recal)\n",
    "tot_f = np.array(tot_fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2,bar_a = plt.subplots(1,3,figsize=(8,3))\n",
    "p_x=0\n",
    "for mod in plot_mod:\n",
    "    bar_a[0].bar(p_x*width, np.nanmean(tot+tot_f,axis=0)[mod_tot.index(mod)], width*.9, label='Successful',color=bar_c[c_x+1], yerr=np.nanstd(tot+tot_f,axis=0)[mod_tot.index(mod)]/tot.shape[0])\n",
    "    bar_a[1].bar(p_x*width, np.nanmean(100*tot/(tot+tot_f),axis=0)[mod_tot.index(mod)], width*.9, label='Successful',color=bar_c[c_x+1], yerr=np.nanstd(100*tot/(tot+tot_f),axis=0)[mod_tot.index(mod)]/tot.shape[0])\n",
    "    p_x+=1\n",
    "for i in range(2):\n",
    "    bar_a[i].set_xticks([])\n",
    "    bar_a[i].set_ylim([0,100])\n",
    "bar_a[0].set_ylabel('Recalibration Frequency (%)')\n",
    "bar_a[1].set_ylabel('Recalibration Efficacy (%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2,bar_a = plt.subplots(1,5,figsize=(10,3))\n",
    "p_x=0\n",
    "for mod in plot_mod:\n",
    "    bar_a[0].bar(p_x*width, np.nanmean(rec_prc+fl_prc,axis=0)[mod_tot.index(mod)], width*.9, label='Successful',color=bar_c[c_x+1], yerr=np.nanstd(rec_prc+fl_prc,axis=0)[mod_tot.index(mod)]/rec_prc.shape[0])\n",
    "    bar_a[1].bar(p_x*width, np.nanmean(100*rec_prc/(rec_prc+fl_prc),axis=0)[mod_tot.index(mod)], width*.9, label='Successful',color=bar_c[c_x+1], yerr=np.nanstd(100*rec_prc/(rec_prc+fl_prc),axis=0)[mod_tot.index(mod)]/rec_prc.shape[0])\n",
    "    p_x+=1\n",
    "for i in range(2):\n",
    "    bar_a[i].set_xticks([])\n",
    "    bar_a[i].set_ylim([0,120])\n",
    "bar_a[1].set_yticklabels([''])\n",
    "# bar_a[0].set_ylabel('Recalibration Frequency (%)')\n",
    "# bar_a[1].set_ylabel('Recalibration Efficacy (%)')\n",
    "\n",
    "\n",
    "# fig2,bar_a = plt.subplots(1,3,figsize=(8,3))\n",
    "p_x=0\n",
    "for mod in plot_mod:\n",
    "    bar_a[2].bar(p_x*width, 100*np.nanmean(sub_base,axis=0)[mod_tot.index(mod)], width*.9, color=bar_c[c_x+1], yerr=100*np.nanstd(sub_base,axis=0)[mod_tot.index(mod)]/7)\n",
    "    bar_a[3].bar(p_x*width, 100*np.nanmean(sub_all,axis=0)[mod_tot.index(mod)], width*.9, color=bar_c[c_x+1], yerr=100*np.nanstd(sub_all,axis=0)[mod_tot.index(mod)]/7)\n",
    "    bar_a[4].bar(p_x*width, np.nanmean(sub_new,axis=0)[mod_tot.index(mod)], width*.9, color=bar_c[c_x+1], yerr=np.nanstd(sub_new,axis=0)[mod_tot.index(mod)]/7)\n",
    "    p_x+=1\n",
    "for bar_i in range(2,5):\n",
    "    bar_a[bar_i].set_xticks([])\n",
    "    bar_a[bar_i].set_ylim([0,120])\n",
    "bar_a[2].set_yticklabels([''])\n",
    "bar_a[3].set_yticklabels([''])\n",
    "bar_a[4].set_yticklabels([''])\n",
    "bar_a[0].set_ylabel('%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ttest_rel(rec_prc[:,mod_tot.index('avcnn')]+fl_prc[:,mod_tot.index('avcnn')],rec_prc[:,mod_tot.index('alda')]+fl_prc[:,mod_tot.index('alda')],axis=0))\n",
    "print(ttest_rel(rec_prc[:,mod_tot.index('avcnn')],rec_prc[:,mod_tot.index('alda')],axis=0))\n",
    "print(ttest_rel(fl_prc[:,mod_tot.index('avcnn')],fl_prc[:,mod_tot.index('alda')],axis=0))\n",
    "print(ttest_rel(rec_prc[:,mod_tot.index('avcnn')]/(rec_prc[:,mod_tot.index('avcnn')]+fl_prc[:,mod_tot.index('avcnn')]),rec_prc[:,mod_tot.index('avcnn')]/(rec_prc[:,mod_tot.index('alda')]+fl_prc[:,mod_tot.index('alda')]),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ttest_rel(tot[:,mod_tot.index('avcnn')]+tot_f[:,mod_tot.index('avcnn')],tot[:,mod_tot.index('alda')]+tot_f[:,mod_tot.index('alda')],axis=0))\n",
    "print(ttest_rel(tot[:,mod_tot.index('avcnn')]/(tot[:,mod_tot.index('avcnn')]+tot_f[:,mod_tot.index('avcnn')]),tot[:,mod_tot.index('avcnn')]/(tot[:,mod_tot.index('alda')]+tot_f[:,mod_tot.index('alda')]),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ttest_rel(tot[:,mod_tot.index('avcnn')]+tot_f[:,mod_tot.index('avcnn')],tot[:,mod_tot.index('acnn05')]+tot_f[:,mod_tot.index('acnn05')],axis=0))\n",
    "print(ttest_rel(tot[:,mod_tot.index('avcnn')]/(tot[:,mod_tot.index('avcnn')]+tot_f[:,mod_tot.index('avcnn')]),tot[:,mod_tot.index('avcnn')]/(tot[:,mod_tot.index('acnn05')]+tot_f[:,mod_tot.index('acnn05')]),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data,columns=['acc','sub','elec','mod'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".05 / (10 - 1 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_n = cp.deepcopy(stat)\n",
    "stat_c = cp.deepcopy(stat)\n",
    "k = 0\n",
    "for i in range(11):\n",
    "    m = np.nanmin(stat_c)\n",
    "    if k == 0:\n",
    "        if m*(10-i) > 0.05:\n",
    "            print('boop:' + str(i))\n",
    "            k = i\n",
    "        else:\n",
    "            stat_n[stat==m] = m*(10-i)\n",
    "            stat_c = stat[stat>np.nanmin(stat_c)]\n",
    "    else:\n",
    "        stat_n[stat==m] = m*(10-k)\n",
    "        stat_c = stat[stat>np.nanmin(stat_c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = rec_prc + fl_prc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = np.zeros((len(plot_mod),len(plot_mod)))\n",
    "stat2 = np.zeros((len(plot_mod),len(plot_mod)))\n",
    "i_i = 0\n",
    "for i in plot_mod:\n",
    "    j_j = 0\n",
    "    for j in plot_mod:\n",
    "        print(i + ', ' + j)\n",
    "        print(str(i_i) + str(j_j))\n",
    "        stat[i_i,j_j] = (ttest_rel(tot[:,mod_tot.index(i)]+tot_f[:,mod_tot.index(i)],tot[:,mod_tot.index(j)]+tot_f[:,mod_tot.index(j)],axis=0))[1]\n",
    "        stat2[i_i,j_j] = (ttest_rel(tot[:,mod_tot.index(i)]/(tot[:,mod_tot.index(i)]+tot_f[:,mod_tot.index(i)]),tot[:,mod_tot.index(j)]/(tot[:,mod_tot.index(j)]+tot_f[:,mod_tot.index(j)]),axis=0))[1]\n",
    "        j_j +=1\n",
    "    i_i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = np.zeros((len(plot_mod),len(plot_mod)))\n",
    "stat2 = np.zeros((len(plot_mod),len(plot_mod)))\n",
    "i_i = 0\n",
    "for i in plot_mod:\n",
    "    j_j = 0\n",
    "    for j in plot_mod:\n",
    "        stat[i_i,j_j] = ttest_rel(sub_new[:,mod_tot.index(i)],sub_new[:,mod_tot.index(j)],axis=0,nan_policy='omit')[1]\n",
    "        j_j +=1\n",
    "    i_i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = np.zeros((len(plot_mod),len(plot_mod)))\n",
    "stat2 = np.zeros((len(plot_mod),len(plot_mod)))\n",
    "i_i = 0\n",
    "for i in plot_mod:\n",
    "    j_j = 0\n",
    "    for j in plot_mod:\n",
    "        print(i + ', ' + j)\n",
    "        print(str(i_i) + str(j_j))\n",
    "        stat[i_i,j_j] = (ttest_rel((rec_prc+fl_prc)[:,mod_tot.index(i)],(rec_prc+fl_prc)[:,mod_tot.index(j)],axis=0))[1]\n",
    "        stat2[i_i,j_j] = (ttest_rel(rec_prc[:,mod_tot.index(i)]/(rec_prc[:,mod_tot.index(i)]+fl_prc[:,mod_tot.index(i)]),rec_prc[:,mod_tot.index(j)]/(rec_prc[:,mod_tot.index(j)]+fl_prc[:,mod_tot.index(j)]),axis=0))[1]\n",
    "        j_j +=1\n",
    "    i_i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in plot_mod:\n",
    "    for j in plot_mod:\n",
    "        print(i + ', ' + j)\n",
    "        print(10*(ttest_rel(tot[:,mod_tot.index(i)]+tot_f[:,mod_tot.index(i)],tot[:,mod_tot.index(j)]+tot_f[:,mod_tot.index(j)],axis=0))[1])\n",
    "        print(10*(ttest_rel(tot[:,mod_tot.index(i)]/(tot[:,mod_tot.index(i)]+tot_f[:,mod_tot.index(i)]),tot[:,mod_tot.index(i)]/(tot[:,mod_tot.index(j)]+tot_f[:,mod_tot.index(j)]),axis=0))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ttest_rel(tot[:,mod_tot.index('avcnn')]+tot_f[:,mod_tot.index('avcnn')],tot[:,mod_tot.index('acnn05')]+tot_f[:,mod_tot.index('acnn05')],axis=0))\n",
    "print(ttest_rel(tot[:,mod_tot.index('avcnn')],tot[:,mod_tot.index('acnn05')],axis=0))\n",
    "print(ttest_rel(tot_f[:,mod_tot.index('avcnn')],tot_f[:,mod_tot.index('acnn05')],axis=0))\n",
    "print(ttest_rel(tot[:,mod_tot.index('avcnn')]/(tot[:,mod_tot.index('avcnn')]+tot_f[:,mod_tot.index('avcnn')]),tot[:,mod_tot.index('avcnn')]/(tot[:,mod_tot.index('acnn05')]+tot_f[:,mod_tot.index('acnn05')]),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ttest_rel(rec_prc[:,mod_tot.index('avcnn')]+fl_prc[:,mod_tot.index('avcnn')],rec_prc[:,mod_tot.index('alda')]+fl_prc[:,mod_tot.index('alda')],axis=0))\n",
    "print(ttest_rel(rec_prc[:,mod_tot.index('avcnn')],rec_prc[:,mod_tot.index('alda')],axis=0))\n",
    "print(ttest_rel(fl_prc[:,mod_tot.index('avcnn')],fl_prc[:,mod_tot.index('alda')],axis=0))\n",
    "print(ttest_rel(rec_prc[:,mod_tot.index('avcnn')]/(rec_prc[:,mod_tot.index('avcnn')]+fl_prc[:,mod_tot.index('avcnn')]),rec_prc[:,mod_tot.index('avcnn')]/(rec_prc[:,mod_tot.index('alda')]+fl_prc[:,mod_tot.index('alda')]),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ttest_rel(rec_prc[:,mod_tot.index('avcnn')]+fl_prc[:,mod_tot.index('avcnn')],rec_prc[:,mod_tot.index('acnn05')]+fl_prc[:,mod_tot.index('acnn05')],axis=0))\n",
    "print(ttest_rel(rec_prc[:,mod_tot.index('avcnn')],rec_prc[:,mod_tot.index('acnn05')],axis=0))\n",
    "print(ttest_rel(fl_prc[:,mod_tot.index('avcnn')],fl_prc[:,mod_tot.index('acnn05')],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(sns.color_palette(\"RdBu\"),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.decomposition import PCA\n",
    "# Count recalibrations\n",
    "path = 'C:/Users/yteh/Documents/work/necal/home data/'\n",
    "subs = os.listdir(path)\n",
    "if 'skip' in subs:\n",
    "    subs = np.delete(subs,subs.index('skip'))\n",
    "bat = 32\n",
    "load_mod = False\n",
    "ft = 'tdar'\n",
    "iter = 10\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "test_mod = 0\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\",category=RuntimeWarning)\n",
    "    sub_b = []\n",
    "    sub_s = []\n",
    "    sub_sep=[]\n",
    "    for sub in range(7):\n",
    "        print(subs[sub])\n",
    "        sub_path = path + subs[sub] + '/DATApost/MAT/'\n",
    "        all_files = os.listdir(sub_path)\n",
    "        if 'skip' in all_files:\n",
    "            all_files = np.delete(all_files,all_files.index('skip'))\n",
    "\n",
    "        # load or initialize cnn weights\n",
    "        acc = np.zeros((len(all_files),2))\n",
    "        acc_val = np.zeros((len(all_files),2))\n",
    "        acc_prev = np.zeros((len(all_files),2))\n",
    "        acc_train = np.zeros((len(all_files),2))\n",
    "        \n",
    "\n",
    "        acc_i = 0\n",
    "\n",
    "        # Loop through files\n",
    "        for i in range(len(all_files)-1):              \n",
    "            # load training file\n",
    "            train_file = all_files[i]\n",
    "            train_data, train_params = prd.load_caps_train(sub_path + train_file + '/traindata.mat')\n",
    "\n",
    "            # load training file\n",
    "            train_data, train_params, th = prd.threshold(train_data, train_params)\n",
    "            val_data, val_params = train_data, train_params\n",
    "                \n",
    "            # get current dofs and create key\n",
    "            if i ==0:\n",
    "                if i == 0:\n",
    "                    train_dof = np.unique(train_params[:,-1])\n",
    "                    key = np.arange(len(train_dof))\n",
    "\n",
    "                    n_dof = len(train_dof)\n",
    "\n",
    "                    h = np.ones((len(all_files),n_dof))\n",
    "                    b = np.ones((len(all_files),n_dof))\n",
    "                    b2 = np.ones((len(all_files)))\n",
    "                    sep = np.zeros((len(all_files),n_dof))\n",
    "                    tot_b = np.ones((len(all_files,)))\n",
    "                    h[:] = np.nan\n",
    "                    b[:] = np.nan\n",
    "                    b2[:] = np.nan\n",
    "                    h2 = cp.deepcopy(b2)\n",
    "                    cl_s = np.zeros((n_dof,))\n",
    "                    cl_s2 = np.zeros((len(all_files),n_dof))\n",
    "                # else:\n",
    "                    prev_ndof = [n_dof, key, train_dof]\n",
    "                    # check if current dofs are all in old dof list\n",
    "                    train_dof = np.unique(train_params[:,-1])\n",
    "                            # print('cur: ' + str(train_dof))\n",
    "                    key = np.zeros((len(train_dof),))\n",
    "                    dof_ovlp = np.isin(train_dof,prev_ndof[2],assume_unique=True)\n",
    "                    temp_dof = cp.deepcopy(train_dof)\n",
    "                    # loop through dofs that are in previous dofs, set the keys\n",
    "                    for dof in train_dof[dof_ovlp]:\n",
    "                        key[train_dof==dof] = prev_ndof[1][prev_ndof[2]==dof]\n",
    "                        temp_dof[train_dof==dof] = prev_ndof[2][prev_ndof[2]==dof]\n",
    "\n",
    "                    # check if previous dofs has classes not in this set\n",
    "                    dof_xtra = ~np.isin(prev_ndof[2],temp_dof,assume_unique=True)\n",
    "                    temp_dof = np.hstack((temp_dof,prev_ndof[2][dof_xtra]))\n",
    "                    key = np.hstack((key,prev_ndof[1][dof_xtra]))\n",
    "\n",
    "                    # loop through dofs that are not in previous dofs (ie new classes), add keys\n",
    "                    key_i = 1\n",
    "                    xtra = False\n",
    "                    for dof in train_dof[~dof_ovlp]:\n",
    "                        print('removing train ' + str(dof))\n",
    "                        ind = train_params[:,-1] == dof\n",
    "                        train_params = train_params[~ind,...]\n",
    "                        train_data = train_data[~ind,...]\n",
    "                        ind = val_params[:,-1] == dof\n",
    "                        val_params = val_params[~ind,...]\n",
    "                        val_data = val_data[~ind,...]\n",
    "                        key = np.delete(key,temp_dof==dof)\n",
    "                        temp_dof = np.delete(temp_dof,temp_dof==dof)\n",
    "\n",
    "                    train_dof = cp.deepcopy(temp_dof)\n",
    "                \n",
    "                key = key.astype(int)\n",
    "\n",
    "                train_data, train_params = lp.check_labels(train_data,train_params,train_dof,key,False)\n",
    "                # print(train_dof)\n",
    "\n",
    "                _, x_clean_cnn, y_clean, _, x_train_cnn, y_train, x_train_lda, y_train_lda, emg_scale, scaler, _, _ = prd.prep_train_caps(train_data, train_params, prop_b=False, batch_size=bat, ft=ft, noise=False, split=False,num_classes=n_dof)\n",
    "\n",
    "                skip = False\n",
    "                for cl in range(len(train_dof)):\n",
    "                    if np.sum(y_train_lda==key[cl]) == 0:\n",
    "                        skip = True\n",
    "                \n",
    "                if not skip:\n",
    "                    w, c, mu_class, _, v, N, cov_class = dlda.train_lda(x_train_lda, y_train_lda, key)\n",
    "                x_train_lda = np.matmul(x_train_lda,v)\n",
    "                # pca = PCA(n_components=5)\n",
    "                # x_train_lda = pca.fit_transform(x_train_lda)\n",
    "\n",
    "                \n",
    "                # cl_s2[:] = np.nan\n",
    "                # cl_s[:] = np.nan\n",
    "                m_cl = np.zeros((n_dof,x_train_lda.shape[1]))\n",
    "                s_cl = np.zeros((n_dof,x_train_lda.shape[1],x_train_lda.shape[1]))\n",
    "                for cl in train_dof:\n",
    "                    train_ind = np.squeeze(y_train_lda == key[train_dof==cl])\n",
    "                    temp_x = x_train_lda[train_ind,...]\n",
    "                    m_cl[key[train_dof==cl],...] = np.nanmean(temp_x,axis=0)\n",
    "                    s_cl[key[train_dof==cl],...] = np.cov(temp_x.T)\n",
    "\n",
    "            #del x_train_lda, y_train_lda, x_train_cnn, y_train, x_clean_cnn, y_clean\n",
    "            \n",
    "            # load data\n",
    "            test_file = all_files[i+1]\n",
    "            test_data, test_params = prd.load_caps_train(sub_path + test_file + '/traindata.mat')\n",
    "            \n",
    "            # check class labels\n",
    "            test_data, test_params, _ = prd.threshold(test_data, test_params, th)\n",
    "            test_data, test_params = lp.check_labels(test_data,test_params,train_dof,key)\n",
    "\n",
    "            # test \n",
    "            y_test, _, x_test_cnn, x_test_lda, y_test_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=n_dof, ft=ft, split=False)\n",
    "            \n",
    "            # test \n",
    "            acc[i+1,:] = lp.test_models(None, None,  x_test_lda, y_test_lda, lda=[w,c])\n",
    "            x_test_lda = np.matmul(x_test_lda,v)\n",
    "            # x_test_lda = pca.transform(x_test_lda)\n",
    "\n",
    "            for cl in train_dof:\n",
    "                test_ind = np.squeeze(y_test_lda == key[train_dof==cl])\n",
    "                train_ind = np.squeeze(y_train_lda == key[train_dof==cl])\n",
    "                m0 = np.nanmean(x_train_lda[train_ind,:],axis=0)\n",
    "                s0 = np.cov(x_train_lda[train_ind,:].T)\n",
    "                if np.sum(test_ind) > 10:\n",
    "                    m2 = np.nanmean(x_test_lda[test_ind,:],axis=0)\n",
    "                    s2 = np.cov(x_test_lda[test_ind,:].T)\n",
    "                    h[i+1,key[train_dof==cl]] = prd.hellinger(m0,s0,m2,s2)\n",
    "                    b[i+1,key[train_dof==cl]] = np.nanmean(prd.mahal(m0,s0,m2,s2))\n",
    "                    ct = 0\n",
    "                    for cl_i in train_dof:\n",
    "                        cl_sep = np.nanmean(prd.mahal(np.squeeze(m_cl[key[train_dof==cl_i],...]),np.squeeze(s_cl[key[train_dof==cl_i],...]),m2,s2))\n",
    "                        if np.isnan(cl_sep):\n",
    "                            print('oops')\n",
    "                        else:\n",
    "                            ct += 1\n",
    "                            sep[i+1,key[train_dof==cl]] += cl_sep\n",
    "                    sep[i+1,key[train_dof==cl]] /= ct\n",
    "\n",
    "                    ct = 0\n",
    "                    for cl_i in train_dof:\n",
    "                        if cl_i != cl:\n",
    "                            temp_ind = np.squeeze(y_test_lda == key[train_dof==cl_i])\n",
    "                            temp_x2 = x_test_lda[temp_ind,...]\n",
    "                            m1 = np.nanmean(temp_x2,axis=0)\n",
    "                            s1 = np.cov(temp_x2.T)\n",
    "                            cl_s2[i+1,key[train_dof==cl]] += np.nanmean(prd.mahal(m1,s1,m2,s2))\n",
    "                            ct+=1\n",
    "                    cl_s2[i+1,key[train_dof==cl]] /= ct\n",
    "                    # b[i+1,key[train_dof==cl]] = prd.bhatta(m1,s1,m2,s2)\n",
    "            # print(h[i+1,:])\n",
    "            m1 = np.nanmean(x_train_lda,axis=0)\n",
    "            s1 = np.cov(x_train_lda.T)\n",
    "            m2 = np.nanmean(x_test_lda,axis=0)\n",
    "            s2 = np.cov(x_test_lda.T)\n",
    "            # print(m1)\n",
    "            # print(m2)\n",
    "            b2[i+1] = np.nanmean(prd.mahal(m1,s1,m2,s2))\n",
    "            h2[i+1] = prd.hellinger(m1,s1,m2,s2)\n",
    "            # print(h2)\n",
    "\n",
    "            print(\"{:.2f}\".format(acc[i+1,0]))\n",
    "            del y_test, x_test_cnn#, x_test_lda, y_test_lda, test_data, test_params\n",
    "\n",
    "        print(np.median(acc,axis=0))\n",
    "        with open(subs[sub] + '_acc_post.p','wb') as f:\n",
    "            pickle.dump([acc,h,b,cl_s,sep,cl_s2,b2,h2],f)\n",
    "        sub_b.append(b)\n",
    "        sub_s.append(cl_s)\n",
    "        sub_sep.append(sep)\n",
    "        \n",
    "        gc.collect(generation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=h2_all\n",
    "y2=acc_all\n",
    "pearsonr(y1[~np.isnan(y1) & ~np.isnan(y2)& ~np.isinf(y1)& ~np.isinf(y2)],y2[~np.isnan(y1) & ~np.isnan(y2)& ~np.isinf(y1)& ~np.isinf(y2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "4\n",
      "0\n",
      "3\n",
      "----\n",
      "3\n",
      "0\n",
      "6\n",
      "8\n",
      "----\n",
      "24\n",
      "6\n",
      "0\n",
      "18\n",
      "----\n",
      "22\n",
      "32\n",
      "1\n",
      "5\n",
      "----\n",
      "3\n",
      "1\n",
      "9\n",
      "10\n",
      "----\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "----\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "sns.set_palette(\"PuBu\")\n",
    "path = 'C:/Users/yteh/Documents/work/necal/home data/'\n",
    "subs = os.listdir(path)\n",
    "if 'skip' in subs:\n",
    "    subs = np.delete(subs,subs.index('skip'))\n",
    "fig,ax = plt.subplots(1,3,figsize=(15,5))\n",
    "figpx,axpx = plt.subplots(figsize=(10,8))\n",
    "figpxy,axpxy = plt.subplots(figsize=(10,8))\n",
    "figc,axc = plt.subplots(figsize=(10,8))\n",
    "fig2,ax2 = plt.subplots()\n",
    "med_acc = []\n",
    "m = ['o','x','^','s','p','D','+']\n",
    "m = ['o','o','x','^','^','s','s']\n",
    "fi = ['none','none','none','none','none','none','none']\n",
    "m = ['x']\n",
    "for i in range(7):\n",
    "    m.append('x')\n",
    "# cmaps = ['Blues','Greens','BuPu','Oranges','Purples','Reds','PuRd']\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\",category=RuntimeWarning)\n",
    "    for sub in range(7):\n",
    "        sub_path = path + subs[sub] + '/DATApre/MAT/'\n",
    "        all_files = os.listdir(sub_path)\n",
    "        if 'skip' in all_files:\n",
    "            all_files = np.delete(all_files,all_files.index('skip'))\n",
    "        num_pre = len(all_files)\n",
    "\n",
    "        with open('lda_hell/' + subs[sub] + '_hell2.p','rb') as f:\n",
    "            acc,h,b,cl_s,sep,cl_s2,b2,h2 = pickle.load(f)\n",
    "        \n",
    "        if sub ==0:\n",
    "            acc_all = acc[1:,0]\n",
    "            h_all = np.nanmean(h[1:,:],axis=1)\n",
    "            h2_all = h2[1:]\n",
    "        else:\n",
    "            acc_all = np.hstack((acc_all,acc[1:,0]))\n",
    "            h_all = np.hstack((h_all,np.nanmean(h[1:,:],axis=1)))\n",
    "            h2_all = np.hstack((h2_all,h2[1:,]))\n",
    "\n",
    "        col = np.array(sns.color_palette(\"GnBu\",acc.shape[0]-1))[:,:]\n",
    "        # print(np.nanmedian(acc[1:num_pre,0]))\n",
    "        # print(np.nanmedian(acc[num_pre:,0]))\n",
    "        # med_acc.extend((np.nanmedian(acc[1:num_pre,0]),np.nanmedian(acc[num_pre:,0])))\n",
    "        # print('---')\n",
    "        min_h = np.nanmax(h[1:,:],axis=1)\n",
    "        norm_m = b/np.nanmean(cl_s)\n",
    "        acc_p = acc[1:,0]\n",
    "        \n",
    "        # fig1,ax1 = plt.subplots(1,3,figsize=(20,5))\n",
    "        # for c in range(acc_p.shape[0]):\n",
    "        #     ax[0].plot(h2[c+1],acc_p[c], m[sub],mew=2,ms=9,label='TR' + str(sub),color=col[c,:],fillstyle=fi[sub])\n",
    "        #     ax[1].plot(np.nanmean(h[c+1,:]),acc_p[c], m[sub],mew=2,ms=9,color=col[c,:],fillstyle=fi[sub])\n",
    "        #     if c == 0:\n",
    "        #         ax[2].plot(h2[c+1],np.nanmean(h[c+1,:]),m[sub],mew=2,ms=9,label='TR' + str(sub+1),color=col[c,:],fillstyle=fi[sub])\n",
    "        #     else:\n",
    "        #         # if c == acc_p.shape[0]-1:\n",
    "        #         #     ax[2].legend()\n",
    "        #         ax[2].plot(h2[c+1],np.nanmean(h[c+1,:]),m[sub],mew=2,ms=9,color=col[c,:],fillstyle=fi[sub])\n",
    "\n",
    "        m_s = np.linspace(0,30,acc_p.shape[0])\n",
    "        h2_low = h2[h2<0.5]\n",
    "        # acc_low = acc_p[]\n",
    "\n",
    "        # for c in range(acc_p.shape[0]-1,-1,-1):\n",
    "        #     axpx.plot(h2[c+1],acc_p[c], 'o',mew=1,ms=m_s[c]+3,label='TR' + str(sub),mec='k',alpha=.7,color=col[c,:])#,color=col[acc_p.shape[0]//2,:])#,fillstyle=fi[sub])\n",
    "        #     axpxy.plot(np.nanmean(h[c+1,:]),acc_p[c], 'o',mew=1,ms=m_s[c]+3,mec='k',alpha=.7,color=col[c,:])#,color=col[acc_p.shape[0]//2,:])#,fillstyle=fi[sub])\n",
    "        #     if c == 0:\n",
    "        #         axc.plot(h2[c+1],np.nanmean(h[c+1,:]),'o',mew=1,ms=m_s[c]+3,label='TR' + str(sub+1),mec='k',alpha=.7,color=col[c,:])#,color=col[acc_p.shape[0]//2,:])#,fillstyle=fi[sub])\n",
    "        #     else:\n",
    "        #         # if c == acc_p.shape[0]-1:\n",
    "        #         #     ax[2].legend()\n",
    "        #         axc.plot(h2[c+1],np.nanmean(h[c+1,:]),'o',mew=1,ms=m_s[c]+3,mec='k',alpha=.7,color=col[c,:])#,color=col[acc_p.shape[0]//2,:])#,fillstyle=fi[sub])\n",
    "\n",
    "        for c in range(num_pre,num_pre+1*(acc_p.shape[0]-num_pre)//4):#,3*acc_p.shape[0]//4):\n",
    "            axpx.plot(h2[c+1],acc_p[c], 'o',mew=1,ms=m_s[c]+3,label='TR' + str(sub),mec='k',alpha=.7,color=col[c,:])#,color=col[acc_p.shape[0]//2,:])#,fillstyle=fi[sub])\n",
    "            axpxy.plot(np.nanmean(h[c+1,:]),acc_p[c], 'o',mew=1,ms=m_s[c]+3,mec='k',alpha=.7,color=col[c,:])#,color=col[acc_p.shape[0]//2,:])#,fillstyle=fi[sub])\n",
    "            if c == 0:\n",
    "                axc.plot(h2[c+1],np.nanmean(h[c+1,:]),'o',mew=1,ms=m_s[c]+3,label='TR' + str(sub+1),mec='k',alpha=.7,color=col[c,:])#,color=col[acc_p.shape[0]//2,:])#,fillstyle=fi[sub])\n",
    "            else:\n",
    "                # if c == acc_p.shape[0]-1:\n",
    "                #     ax[2].legend()\n",
    "                axc.plot(h2[c+1],np.nanmean(h[c+1,:]),'o',mew=1,ms=m_s[c]+3,mec='k',alpha=.7,color=col[c,:])#,color=col[acc_p.shape[0]//2,:])#,fillstyle=fi[sub])\n",
    "        \n",
    "        print(np.sum(np.array(np.where(h2 > .5))>h2.shape[0]//2))\n",
    "        print(np.sum(np.array(np.where(h2 > .5))<h2.shape[0]//2))\n",
    "        print(np.sum(np.array(np.where(h2 < .5))>h2.shape[0]//2))\n",
    "        print(np.sum(np.array(np.where(h2 < .5))<h2.shape[0]//2))\n",
    "        print('----')\n",
    "        # print(h2.shape)\n",
    "\n",
    "        axc.set_ylim([-1,2])\n",
    "        axpx.set_xlim([-.1,1.1])\n",
    "        axpx.set_ylim([-10,110])\n",
    "        # axpx.axhline(50, ls='--', color='grey')\n",
    "        axpxy.set_ylim([-10,110])\n",
    "        # axpxy.axhline(50, ls='--', color='grey')\n",
    "        axpx.set_ylabel('Accuracy (%)')\n",
    "        axpx.set_xlabel('Hellinger Distance P(X1) - P(X2)')\n",
    "        axpxy.set_xlabel('Hellinger Distance P(X1|Y) - P(X2|Y)')\n",
    "        axc.set_xlabel('Hellinger Distance P(X1) - P(X2)')\n",
    "        axc.set_ylabel('Hellinger Distance P(X1|Y) - P(X2|Y)')\n",
    "\n",
    "        ax[2].set_ylim([0,1.1])\n",
    "        ax[2].set_xlim([0,1.1])\n",
    "        ax[0].set_ylim([0,100])\n",
    "        ax[0].axhline(50, ls='--', color='grey')\n",
    "        ax[1].set_ylim([0,100])\n",
    "        ax[1].axhline(50, ls='--', color='grey')\n",
    "        ax[0].set_ylabel('Accuracy (%)')\n",
    "        ax[0].set_xlabel('Hellinger Distance P(X1) - P(X2)')\n",
    "        ax[1].set_xlabel('Hellinger Distance P(X1|Y) - P(X2|Y)')\n",
    "        ax[2].set_xlabel('Hellinger Distance P(X1) - P(X2)')\n",
    "        ax[2].set_ylabel('Hellinger Distance P(X1|Y) - P(X2|Y)')\n",
    "        # for a in range(3):\n",
    "        #     ax[a].set_xticks([0,.2,.4,.6,.8,1])\n",
    "            \n",
    "\n",
    "        # ax.set_xlim([-6,0])\n",
    "        # ax.plot(b2[1:],acc_p, 'x')\n",
    "        # ax1[0].plot(h2[1:], 'x',mew=2,ms=7)\n",
    "        # ax1[1].plot(np.nanmean(h[1:,:],axis=1),  'x',mew=2,ms=7)\n",
    "        # ax1[2].plot(acc_p, 'x',mew=2,ms=7)\n",
    "        # ax1[2].set_ylim([0,100])\n",
    "        # ax1[0].set_ylim([0,1])\n",
    "        # ax1[1].set_ylim([0,1])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(h2 > .6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for sub in range(7):\n",
    "    with open(subs[sub] + '_lda_accs.p','rb') as f:\n",
    "        acc, _ = pickle.load(f)\n",
    "    temp.append(acc[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count recalibrations\n",
    "path = 'C:/Users/yteh/Documents/work/necal/home data/'\n",
    "subs = os.listdir(path)\n",
    "if 'skip' in subs:\n",
    "    subs = np.delete(subs,subs.index('skip'))\n",
    "bat = 128\n",
    "load_mod = False\n",
    "mod_tot = ['blda','lda','crlda','alda','bcnn','cnn', 'crcnn','acnn03','acnn30','acewc00','acewc30', 'adcnn30', 'vcnn', 'bvcnn', 'avcnn03', 'avcnn15', 'acnnl03','crvcnn','acewclm','xtra','xtra1','xtra2']\n",
    "ft = 'feat'\n",
    "iter = 1\n",
    "\n",
    "for sub in range(4,5):\n",
    "    print(subs[sub])\n",
    "    sub_path = path + subs[sub] + '/DATA/MAT/'\n",
    "    all_files = os.listdir(sub_path)\n",
    "    if 'skip' in all_files:\n",
    "        all_files = np.delete(all_files,all_files.index('skip'))\n",
    "\n",
    "    # first iteration, includes LDA; others exclude LDA\n",
    "    mod_all = ['vcnn']\n",
    "\n",
    "    # load or initialize cnn weights\n",
    "    if load_mod:\n",
    "        with open(subs[sub] + '_' + str(0) + '_r_accs.p','rb') as f:\n",
    "            all_acc, all_recal, all_val, all_prev, all_train, all_times, _, _, c_weights, cl_wc, scaler_0, emg_scale = pickle.load(f)\n",
    "        all_times = np.zeros((len(all_files),len(mod_tot)))\n",
    "    else:\n",
    "        c_weights = None\n",
    "        v_weights = None\n",
    "        v_wc = None\n",
    "        cl_wc = None\n",
    "        all_recal = np.empty((len(mod_tot),1))\n",
    "        all_recal[:] = np.nan\n",
    "        all_acc = np.zeros((len(all_files),len(mod_tot)))\n",
    "        all_val = np.zeros((len(all_files),len(mod_tot)))\n",
    "        all_prev = np.zeros((len(all_files),len(mod_tot)))\n",
    "        all_train = np.zeros((len(all_files),len(mod_tot)))\n",
    "        all_times = np.zeros((len(all_files),len(mod_tot)))\n",
    "\n",
    "    mod_i = 0\n",
    "    for mod in mod_all:\n",
    "        acc = np.zeros((len(all_files),5))\n",
    "        acc_val = np.zeros((len(all_files),5))\n",
    "        acc_prev = np.zeros((len(all_files),5))\n",
    "        acc_train = np.zeros((len(all_files),5))\n",
    "\n",
    "        if 'cnn' in mod:\n",
    "            acc_i = 2\n",
    "        elif 'cewc' in mod:\n",
    "            acc_i = 4\n",
    "        elif 'lda' in mod:\n",
    "            acc_i = 0\n",
    "\n",
    "        cnn = None\n",
    "        ewc = None\n",
    "\n",
    "        ep = 50\n",
    "        recal = 0\n",
    "        skip = False\n",
    "\n",
    "        # Loop through files\n",
    "        for i in range(1,2):#len(all_files)-1):\n",
    "            # load training file\n",
    "            train_file = all_files[i]\n",
    "            train_data, train_params = prd.load_caps_train(sub_path + train_file + '/traindata.mat')\n",
    "\n",
    "            train_data, train_params, th = prd.threshold(train_data, train_params)\n",
    "            val_data = train_data\n",
    "            val_params = train_params\n",
    "\n",
    "            train_dof = np.unique(train_params[:,-1])\n",
    "            key = np.empty(train_dof.shape)\n",
    "            for key_i in range(len(train_dof)):\n",
    "                key[key_i] = cp.deepcopy(train_params[np.argmax(train_params[:,2] == train_dof[key_i]),0])\n",
    "            n_dof = int(np.max(key))\n",
    "            \n",
    "            train_data, train_params = lp.check_labels(train_data,train_params,train_dof,key)\n",
    "            val_data, val_params = lp.check_labels(val_data,val_params,train_dof,key)\n",
    "\n",
    "            _, x_clean_cnn, y_clean, _, x_train_cnn, y_train, x_train_lda, y_train_lda, emg_scale, scaler, _, _, _ = prd.prep_train_caps(train_data, train_params, prop_b=False, batch_size=bat, ft=ft, noise=True, split=False,num_classes=n_dof)\n",
    "\n",
    "            _, _, _, _, x_val_cnn, y_val, x_val_lda, y_val_lda, _, _, _, _, _ = prd.prep_train_caps(val_data, val_params, emg_scale=emg_scale,scaler=scaler, prop_b=False, batch_size=bat, ft=ft, num_classes=n_dof, noise=False, split=False)\n",
    "\n",
    "            del train_data, train_params, val_data, val_params\n",
    "\n",
    "            cnn, all_times[i,mod_tot.index(mod)] = lp.train_models(traincnn=x_train_cnn,y_train=y_train, mod=['vcnn'], n_dof=n_dof, ep=30, dec=True, print_b=True)\n",
    "            cnn, all_times[i,mod_tot.index(mod)] = lp.train_models(traincnn=x_train_cnn,y_train=y_train, mod=[cnn], n_dof=n_dof, ep=30, dec=False,print_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = cp.deepcopy(x_clean_cnn)\n",
    "for cl in range(y_clean.shape[1]):\n",
    "    x_out[y_clean[:,cl]==1,...] = np.random.normal(np.mean(x_clean_cnn[y_clean[:,cl]==1,...],axis=0), np.std(x_clean_cnn[y_clean[:,cl]==1,...],axis=0),x_clean_cnn[y_clean[:,cl]==1,...].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = cp.deepcopy(x_train_cnn)\n",
    "for cl in range(y_train.shape[1]):\n",
    "    x_out[y_train[:,cl]==1,...] = np.random.normal(np.mean(x_train_cnn[y_train[:,cl]==1,...],axis=0), np.std(x_train_cnn[y_train[:,cl]==1,...],axis=0),x_train_cnn[y_train[:,cl]==1,...].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp1 = np.ones((1*y_clean.shape[0],8))\n",
    "x_out,_,_ = cnn.dec(samp1,np.tile(np.argmax(y_clean,axis=1),[1]).astype('float32'),samp=True)\n",
    "# _,x_out,_,_ = cnn(x_clean_cnn,np.tile(np.argmax(y_clean,axis=1),[1]).astype('float32'),dec=True)\n",
    "x_out = x_out.numpy()\n",
    "# for i in range(y_clean.shape[1]):\n",
    "#     adjust1 = np.std(x_clean_cnn[np.argmax(y_clean,axis=1)==i,...],axis=0)\n",
    "#     rescale = np.mean(adjust1)/np.mean(np.std(x_out[np.argmax(y_clean,axis=1)==i,...],axis=0))\n",
    "#     gmean = np.mean(x_out[np.argmax(y_clean,axis=1)==i,...],axis=0)\n",
    "#     x_out[np.argmax(y_clean,axis=1)==i,...] = (x_out[np.argmax(y_clean,axis=1)==i,...] - gmean)*rescale + gmean\n",
    "# x_out = np.maximum(np.minimum(x_out,1),0)\n",
    "for cl in range(y_clean.shape[1]):\n",
    "    ind = np.tile(np.argmax(y_clean,axis=1)==cl,[1])\n",
    "    ind2 = np.argmax(y_clean,axis=1)==cl\n",
    "    x_temp = x_out[ind,...].reshape((np.sum(ind),-1))\n",
    "    x_true = x_clean_cnn[ind2,...].reshape((np.sum(ind2),-1))\n",
    "    # for i in range()\n",
    "    plt.figure()\n",
    "    # for i in range(x_true.shape[0]):\n",
    "    #     plt.plot(x_true[i,...],'k-')\n",
    "        \n",
    "    for i in range(x_temp.shape[0]):\n",
    "        plt.plot(x_temp[i,...],'b-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lda = x_clean_cnn.reshape(x_clean_cnn.shape[0],-1)\n",
    "y_lda = np.argmax(y_clean,axis=1)[...,np.newaxis]\n",
    "y_train_lda = np.argmax(y_clean,axis=1)[...,np.newaxis]\n",
    "w,c, _, _, _, _, _ = dlda.train_lda(x_lda,y_lda)\n",
    "y_out = dlda.predict(x_lda, w, c)\n",
    "print(dlda.eval_lda(w, c, x_lda, y_lda))\n",
    "x_out_lda = x_out.reshape(x_out.shape[0],-1)\n",
    "print(dlda.eval_lda(w,c, x_out_lda,np.tile(y_train_lda,[1,1])))\n",
    "w,c, _, _, _, _, _ = dlda.train_lda(x_out_lda,np.tile(y_train_lda,[1,1]))\n",
    "print(dlda.eval_lda(w, c, x_out_lda,y_train_lda))\n",
    "print(dlda.eval_lda(w, c, x_lda, np.argmax(y_clean,axis=1)[...,np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1, _ = lp.train_models(traincnn=x_train_cnn,y_train=y_train, mod=['vcnn'], n_dof=n_dof, ep=15, dec=False,print_b=True)\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\"test_accuracy\")\n",
    "test_mod = dl.get_test(cnn1,test_accuracy)\n",
    "print(lp.test_models(x_out, y_clean, None, None, cnn=cnn1, test_mod=test_mod, test_accuracy=test_accuracy))\n",
    "\n",
    "cnn2, _ = lp.train_models(traincnn=x_out,y_train=y_clean, mod=['vcnn'], n_dof=n_dof, ep=15, dec=False,print_b=True)\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name=\"test_accuracy\")\n",
    "test_mod = dl.get_test(cnn2,test_accuracy)\n",
    "print(lp.test_models(x_clean_cnn, y_clean, None, None, cnn=cnn2, test_mod=test_mod, test_accuracy=test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_iter = 1\n",
    "fig,ax = plt.subplots(1,5,figsize=(30,4))\n",
    "for sub in range(2,3):#,5):\n",
    "    with open(subs[sub] + '_0_r_accs.p','rb') as f:\n",
    "        acc_all, recal_all, cur_all, prev_all, val_all, mod_all, mod_tot, c_weights, cl_wc, scaler_0, emg_scale= pickle.load(f)\n",
    "\n",
    "    # mod_all = ['ld','bld','bcnnl','cnnl','acnnl','acnnl3','acnnl30','acewcl']\n",
    "    colors =  cm.get_cmap('tab20c')\n",
    "    c = np.empty((20,4))\n",
    "    for i in range(20):\n",
    "        c[i,:] = colors(i*1/20)\n",
    "\n",
    "\n",
    "    nn_c = np.vstack((np.zeros((1,4)),c[8,:],c[0,:],c[9,:],c[1,:],c[10,:],c[2,:]))\n",
    "    nn_c = np.vstack((np.zeros((1,4)),c[8,:],c[0,:],c[8,:],c[0,:],c[8,:],c[0,:],c[8,:],c[0,:],c[8,:],c[0,:]))\n",
    "    nn_c[0,-1] = 1\n",
    "    all_m = ['ko-','o-','o-','s-','s-','v-','v-']\n",
    "    pt_m = ['ko-','o-','o-','o-','s','s','s','s','D']\n",
    "    nn_c = np.vstack((np.array([0,0,0,1]), c[0,:],c[1,:],c[2,:],c[3,:],c[4,:],c[5,:],c[6,:],c[0,:],c[8,:],c[0,:]))\n",
    "    # nn_c[0,-1] = 1\n",
    "\n",
    "    labels = ['lda','mlp','cnn','a-mlp','a-cnn','ewc-mlp','ewc-cnn','c-mlp','c-cnn','c-ld']\n",
    "    labels = ['r-lda','lda','cnn','r-cnn','a-cnn-5','a-cnn-3','a-cnn-30','ewc-cnn']\n",
    "    # labels = mod_tot\n",
    "\n",
    "    ax_ind = sub\n",
    "    it = 0\n",
    "    for v in [1,2]: \n",
    "        i = mod_tot.index(mod_all[v])\n",
    "        acc_temp = acc_all[1:-1,i]\n",
    "        if not np.isnan(acc_temp).all():\n",
    "            x = np.arange(len(acc_temp))\n",
    "            recal_i = (acc_temp < 0)\n",
    "            ax[ax_ind].plot(np.abs(acc_temp),'-',color=nn_c[it,:])\n",
    "            ax[ax_ind].plot(x[~recal_i],np.abs(acc_temp[~recal_i]),pt_m[it],label=labels[v],color=nn_c[it,:])\n",
    "            ax[ax_ind].plot(x[recal_i],np.abs(acc_temp[recal_i]),'x',ms=10,color=nn_c[it,:])\n",
    "            it+=1\n",
    "\n",
    "    for i in range(5):\n",
    "        ax[i].axhline(70, ls='--', color='grey')\n",
    "        \n",
    "        ax[i].set_ylim([0,100])\n",
    "        ax[i].set_title('TR' + str(i+1))\n",
    "    ax[0].legend()\n",
    "    ax[2].set_xlabel('Calibration Set')\n",
    "    ax[0].set_ylabel('Accuracy (%)')\n",
    "    plt.rc('font', size=15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_iter = 1\n",
    "for sub in range(2,3):#,5):\n",
    "    fig,ax = plt.subplots(1,4,figsize=(20,4))\n",
    "    for it in range(0,cv_iter):\n",
    "        with open(subs[sub] + '_' + str(it) + '_r_accs.p','rb') as f:\n",
    "            # acc_all, recal_all = pickle.load(f)\n",
    "            acc_all, recal_all, cur_all, prev_all, val_all,mod_all, mod_tot, c_weights, cl_wc, scaler_0, emg_scale= pickle.load(f)\n",
    "\n",
    "        # mod_all = ['ld','bld','bcnnl','cnnl','acnnl','acnnl3','acnnl30','acewcl']\n",
    "        colors =  cm.get_cmap('tab20c')\n",
    "        c = np.empty((20,4))\n",
    "        for i in range(20):\n",
    "            c[i,:] = colors(i*1/20)\n",
    "\n",
    "\n",
    "        nn_c = np.vstack((np.zeros((1,4)),c[8,:],c[0,:],c[9,:],c[1,:],c[10,:],c[2,:]))\n",
    "        nn_c = np.vstack((np.zeros((1,4)),c[8,:],c[0,:],c[8,:],c[0,:],c[8,:],c[0,:],c[8,:],c[0,:],c[8,:],c[0,:]))\n",
    "        nn_c[0,-1] = 1\n",
    "        all_m = ['ko-','o-','o-','s-','s-','v-','v-']\n",
    "        pt_m = ['ko','*','*','o','s','s','s','s','D']\n",
    "        pt_m = ['ko','*','*','o','s','s','s','s','D']\n",
    "        nn_c = np.vstack((np.array([0,0,0,1]),np.array([0,0,0,1]), c[0,:],c[1,:],c[4,:],c[5,:],c[6,:],c[8,:],c[6,:],c[0,:],c[8,:],c[0,:]))\n",
    "\n",
    "        labels = ['lda','mlp','cnn','a-mlp','a-cnn','ewc-mlp','ewc-cnn','c-mlp','c-cnn','c-ld']\n",
    "        labels = ['r-lda','lda','cnn','r-cnn','a-cnn-5','a-cnn-3','a-cnn-30','ewc-cnn']\n",
    "        # labels = mod_tot\n",
    "\n",
    "        ax_ind = [1,0,0,1,2,2,2,2,2,2,2,2,3,3,3,3]\n",
    "        it = 0\n",
    "        for v in range(len(mod_all)):\n",
    "            i = mod_tot.index(mod_all[v])\n",
    "            acc_temp = acc_all[1:-1,i]\n",
    "            if not np.isnan(acc_temp).all():\n",
    "                x = np.arange(len(acc_temp))\n",
    "                recal_i = (acc_temp < 0)\n",
    "                ax[ax_ind[it]].plot(np.abs(acc_temp),'-',color=nn_c[it,:])\n",
    "                ax[ax_ind[it]].plot(x[~recal_i],np.abs(acc_temp[~recal_i]),pt_m[it],label=labels[it]+': ' + str(int(recal_all[i,0])),color=nn_c[it,:])\n",
    "                ax[ax_ind[it]].plot(x[recal_i],np.abs(acc_temp[recal_i]),'x',ms=10,color=nn_c[it,:])\n",
    "                it+=1\n",
    "\n",
    "    for i in range(4):\n",
    "        ax[i].axhline(70, ls='--', color='grey')\n",
    "        ax[i].legend()\n",
    "        ax[i].set_ylim([0,100])\n",
    "    ax[0].set_ylabel('Accuracy (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "cv_iter = 1\n",
    "for sub in range(0,5):\n",
    "    fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "    for it in range(0,cv_iter):\n",
    "        with open(subs[sub] + '_' + str(it) + '_r_accs.p','rb') as f:\n",
    "            # acc_all, recal_all = pickle.load(f)\n",
    "            acc_all, recal_all, cur_all, prev_all, mod_all, mod_tot, c_weights, cl_wc, scaler_0, emg_scale= pickle.load(f)\n",
    "\n",
    "        # mod_all = ['ld','bld','bcnnl','cnnl','acnnl','acnnl3','acnnl30','acewcl']\n",
    "        colors =  cm.get_cmap('tab20c')\n",
    "        c = np.empty((20,4))\n",
    "        for i in range(20):\n",
    "            c[i,:] = colors(i*1/20)\n",
    "\n",
    "\n",
    "        nn_c = np.vstack((np.zeros((1,4)),c[8,:],c[0,:],c[9,:],c[1,:],c[10,:],c[2,:]))\n",
    "        nn_c = np.vstack((np.zeros((1,4)),c[8,:],c[0,:],c[8,:],c[0,:],c[8,:],c[0,:],c[8,:],c[0,:],c[8,:],c[0,:]))\n",
    "        nn_c[0,-1] = 1\n",
    "        all_m = ['ko-','o-','o-','s-','s-','v-','v-']\n",
    "        pt_m = ['ko','o','*','o','s','D','s','s','D']\n",
    "        nn_c = np.vstack((np.array([0,0,0,1]),np.array([0,0,0,1]), c[0,:],c[1,:],c[4,:],c[5,:],c[6,:],c[8,:],c[6,:],c[0,:],c[8,:],c[0,:]))\n",
    "\n",
    "        labels = ['lda','mlp','cnn','a-mlp','a-cnn','ewc-mlp','ewc-cnn','c-mlp','c-cnn','c-ld']\n",
    "        labels = ['r-lda','lda','cnn','r-cnn','a-cnn-5','a-cnn-3','a-cnn-30','ewc-cnn']\n",
    "        labels = ['r-lda','lda','cnn','r-cnn','f-cnn-5','f-cnn-3','f-cnn-30','ewc-cnn']\n",
    "        # labels = mod_tot\n",
    "\n",
    "        ax_ind = [0,0,1,1,1,1,2,2,2,2,2,2,3,3,3,3]\n",
    "        it = 0\n",
    "        for v in [0, 3, 5, 4, 6, 7]: #range(len(mod_all)):\n",
    "            i = mod_tot.index(mod_all[v])\n",
    "            acc_temp = acc_all[1:-1,i]\n",
    "            if not np.isnan(acc_temp).all():\n",
    "                x = np.arange(len(acc_temp))\n",
    "                recal_i = (acc_temp < 0)\n",
    "                ax[ax_ind[it]].plot(np.abs(acc_temp),'-',color=nn_c[v,:])\n",
    "                ax[ax_ind[it]].plot(x[~recal_i],np.abs(acc_temp[~recal_i]),pt_m[it],label=labels[v]+': ' + str(int(recal_all[i,0])),color=nn_c[v,:])\n",
    "                ax[ax_ind[it]].plot(x[recal_i],np.abs(acc_temp[recal_i]),'x',ms=10,color=nn_c[v,:])\n",
    "                ax[ax_ind[it]].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "                it+=1\n",
    "\n",
    "    for i in range(2):\n",
    "        ax[i].axhline(70, ls='--', color='grey')\n",
    "        ax[i].legend()\n",
    "        ax[i].set_ylim([0,100])\n",
    "        \n",
    "\n",
    "    ax[0].set_ylabel('Accuracy (%)')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96e4d54467b05e62951c9fd7929782b99429e3b62c1a3b146d4f3dbf79f907e6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('adapt_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
