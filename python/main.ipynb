{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gpu import set_gpu\n",
    "import numpy as np\n",
    "import os\n",
    "import adapt.utils.data_utils as prd\n",
    "import adapt.loop as lp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import adapt.ml.dl_subclass as dl\n",
    "import tensorflow as tf\n",
    "\n",
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/yteh/Documents/work/necal/home data/TR58/DATA/MAT/'\n",
    "all_files = os.listdir(path)\n",
    "train_file = all_files[0]\n",
    "train_file2 = all_files[1]\n",
    "ft= 'feat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = np.delete(all_files,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_params = prd.load_caps_train(path + train_file + '/traindata.mat')\n",
    "train_data = train_data[:,:8,:]\n",
    "\n",
    "train_dof = np.unique(train_params[:,2])\n",
    "key = np.empty(train_dof.shape)\n",
    "for i in range(len(train_dof)):\n",
    "    key[i] = train_params[np.argmax(train_params[:,2] == train_dof[i]),0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2, train_params2 = prd.load_caps_train(path + train_file2 + '/traindata.mat')\n",
    "train_data2 = train_data2[:,:8,:]\n",
    "# train_data = np.vstack((train_data,train_data2))\n",
    "# train_params = np.vstack((train_params,train_params2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial training\n",
    "ep = 30\n",
    "n_dof = len(train_dof)\n",
    "\n",
    "trainmlp, traincnn, y_train, x_train_mlp, x_train_cnn, x_train_lda, y_train_lda, emg_scale, scaler, _, _, _ = prd.prep_train_caps(train_data, train_params, prop_b = False, batch_size=128,ft=ft, noise=False)\n",
    "mlp, cnn, w, c = lp.train_models(traincnn, trainmlp, x_train_lda, y_train_lda, n_dof, ep=ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all controllers without recalibration or adaptation\n",
    "acc = np.empty((len(all_files),3))\n",
    "\n",
    "for i in range(1,len(all_files)):\n",
    "    # load data\n",
    "    test_file = all_files[i]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data,test_params,train_dof,key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=len(train_dof),ft=ft)\n",
    "    acc[i,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, w, c)\n",
    "\n",
    "    print ('Set: ' + test_file, f'CNN Accuracy: {acc[i,2]:.2f},', f'MLP Accuracy: {acc[i,1]:.2f},', f'LDA Accuracy: {acc[i,0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ewc = dl.EWC()\n",
    "test_ewc.call(x_train_mlp[:1,...])\n",
    "test_ewc.star(mlp)\n",
    "test_ewc.compute_diag_fim(x_train_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = dl.MLP(n_class=n_dof)\n",
    "mlp2.call(x_train_mlp[:1,...])\n",
    "mlp2.set_weights(mlp.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 30\n",
    "\n",
    "lam = 50\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_loss2 = tf.keras.metrics.Mean(name='train_loss2')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "train_ewc = dl.get_train_ewc()\n",
    "# check class labels\n",
    "train_data2, train_params2 = lp.check_labels(train_data2, train_params2, train_dof, key)\n",
    "trainmlp2, traincnn2, y_train2, x_train_mlp2, x_train_cnn2, x_train_lda2, y_train_lda2, emg_scale2, scaler2, _, _, _ = prd.prep_train_caps(train_data2, train_params2, prop_b = False, num_classes=n_dof, batch_size=128, noise=False, scaler=scaler, emg_scale=emg_scale,ft=ft)\n",
    "\n",
    "for epoch in range(ep):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    for x, y, _ in trainmlp2:\n",
    "        train_ewc(x, y, test_ewc, optimizer, train_loss, train_loss2, train_accuracy, lam=lam)\n",
    "    if epoch == 0 or epoch == ep-1:\n",
    "        print(f'Epoch {epoch + 1}, ', f'Loss: {train_loss.result():.2f}, ', f'Accuracy: {train_loss2.result() * 1:.2f} ')\n",
    "\n",
    "train_loss.reset_states()\n",
    "train_accuracy.reset_states()\n",
    "mlp2, cnn2, w2, c2 = lp.train_models(traincnn2, trainmlp2, x_train_lda2, y_train_lda2, n_dof, ep, mlp2, cnn,print_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(train_data, train_params, scaler, emg_scale, num_classes=n_dof,ft=ft)\n",
    "y_test2, x_test_mlp2, x_test_cnn2, x_lda2, y_lda2 = prd.prep_test_caps(train_data2, train_params2, scaler2, emg_scale2, num_classes=n_dof,ft=ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mod = dl.get_test()\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "test_mod(x_test_mlp, y_test, mlp, test_loss, test_accuracy)\n",
    "print(test_accuracy.result()*100)\n",
    "\n",
    "test_mod = dl.get_test()\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "test_mod(x_test_mlp2, y_test2, mlp, test_loss, test_accuracy)\n",
    "print(test_accuracy.result()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mod = dl.get_test()\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "test_mod(x_test_mlp, y_test, mlp2, test_loss, test_accuracy)\n",
    "print(test_accuracy.result()*100)\n",
    "\n",
    "test_mod = dl.get_test()\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "test_mod(x_test_mlp2, y_test2, mlp2, test_loss, test_accuracy)\n",
    "print(test_accuracy.result()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mod = dl.get_test()\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "test_mod(x_test_mlp, y_test, test_ewc, test_loss, test_accuracy)\n",
    "print(test_accuracy.result()*100)\n",
    "\n",
    "test_mod = dl.get_test()\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "test_mod(x_test_mlp2, y_test2, test_ewc, test_loss, test_accuracy)\n",
    "print(test_accuracy.result()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all controllers with adaptation\n",
    "ep = 5\n",
    "# Remove extra file if odd number of files\n",
    "if len(all_files)%2 == 0:\n",
    "    all_files = np.delete(all_files,-1)\n",
    "adapt_acc = np.empty((len(all_files),3))\n",
    "adapt_acc[:] = np.nan\n",
    "n_dof = len(train_dof)\n",
    "\n",
    "for i in range(1,len(all_files)-1,2):\n",
    "    # load recalibration data\n",
    "    adapt_file = all_files[i]\n",
    "    adapt_data, adapt_params = prd.load_caps_train(path + adapt_file + '/traindata.mat')\n",
    "    adapt_data = adapt_data[:,:8,:]\n",
    "\n",
    "    # check class labels\n",
    "    adapt_data, adapt_params = lp.check_labels(adapt_data, adapt_params, train_dof, key)\n",
    "    \n",
    "    adaptmlp, adaptcnn, _, _, _, x_train_lda, y_train_lda, emg_scale, scaler, _, _, _ = prd.prep_train_caps(adapt_data, adapt_params, prop_b = False, num_classes=n_dof, batch_size=16, noise=True, scaler=scaler, emg_scale=emg_scale,ft=ft)\n",
    "    mlp, cnn, w, c = lp.train_models(adaptcnn, adaptmlp, x_train_lda, y_train_lda, n_dof, ep, mlp, cnn)\n",
    "    \n",
    "    # load data\n",
    "    test_file = all_files[i+1]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data, test_params, train_dof, key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=n_dof,ft=ft)\n",
    "    adapt_acc[i+1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, w, c)\n",
    "\n",
    "    print ('Adapt: ' + adapt_file + ', Test: ' + test_file, f', CNN Accuracy: {adapt_acc[i+1,2]:.2f},', f'MLP Accuracy: {adapt_acc[i+1,1]:.2f},', f'LDA Accuracy: {adapt_acc[i+1,0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all controllers with recalibration\n",
    "ep = 30\n",
    "# Remove extra file if odd number of files\n",
    "if len(all_files)%2 == 0:\n",
    "    all_files = np.delete(all_files,-1)\n",
    "recal_acc = np.empty((len(all_files),3))\n",
    "recal_acc[:] = np.nan\n",
    "\n",
    "for i in range(1,len(all_files)-1,2):\n",
    "    # load recalibration data\n",
    "    recal_file = all_files[i]\n",
    "    recal_data, recal_params = prd.load_caps_train(path + recal_file + '/traindata.mat')\n",
    "    recal_data = recal_data[:,:8,:]\n",
    "\n",
    "    recal_dof = np.unique(recal_params[:,2])\n",
    "    recal_key = np.empty(recal_dof.shape)\n",
    "    for dof_i in range(len(recal_dof)):\n",
    "        recal_key[dof_i] = recal_params[np.argmax(recal_params[:,2] == recal_dof[dof_i]),0]\n",
    "    n_recal_dof = len(recal_dof)\n",
    "    \n",
    "    recalmlp, recalcnn, _, _, _, x_train_lda, y_train_lda, emg_scale, scaler, _, _, _ = prd.prep_train_caps(recal_data, recal_params, prop_b = False,ft=ft,batch_size=32)\n",
    "    mlp, cnn, w, c = lp.train_models(recalcnn, recalmlp, x_train_lda, y_train_lda, n_recal_dof, ep)\n",
    "    \n",
    "    # load data\n",
    "    test_file = all_files[i+1]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data,test_params,recal_dof,recal_key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=n_recal_dof,ft=ft)\n",
    "    recal_acc[i+1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, w, c)\n",
    "\n",
    "    print ('Recal: ' + recal_file + ', Test: ' + test_file, f', CNN Accuracy: {recal_acc[i+1,2]:.2f},', f'MLP Accuracy: {recal_acc[i+1,1]:.2f},', f'LDA Accuracy: {recal_acc[i+1,0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all controllers with adaptation\n",
    "ep = 15\n",
    "# Remove extra file if odd number of files\n",
    "if len(all_files)%2 == 0:\n",
    "    all_files = np.delete(all_files,-1)\n",
    "align_acc = np.empty((len(all_files),3))\n",
    "align_acc[:] = np.nan\n",
    "n_dof = len(train_dof)\n",
    "\n",
    "for i in range(1,len(all_files)-1,2):\n",
    "    # load recalibration data\n",
    "    align_file = all_files[i]\n",
    "    align_data, align_params = prd.load_caps_train(path + align_file + '/traindata.mat')\n",
    "    align_data = align_data[:,:8,:]\n",
    "\n",
    "    # check class labels\n",
    "    align_data, align_params = lp.check_labels(align_data, align_params, train_dof, key)\n",
    "    \n",
    "    alignmlp, aligncnn, _, _, _, x_train_lda, y_train_lda, emg_scale, scaler, _, _, _ = prd.prep_train_caps(align_data, align_params, prop_b = False, num_classes=n_dof, batch_size=64, noise=True, scaler=scaler, emg_scale=emg_scale,ft=ft)\n",
    "    mlp, cnn, mlp_ali, cnn_ali, w, c = lp.train_models(aligncnn, alignmlp, x_train_lda, y_train_lda, n_dof, ep, mlp, cnn, align=True)\n",
    "    \n",
    "    # load data\n",
    "    test_file = all_files[i+1]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data, test_params, train_dof, key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=n_dof,ft=ft)\n",
    "    align_acc[i+1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, w, c, cnn_align=cnn_ali, mlp_align=mlp_ali)\n",
    "\n",
    "    print ('Align: ' + align_file + ', Test: ' + test_file, f', CNN Accuracy: {align_acc[i+1,2]:.2f},', f'MLP Accuracy: {align_acc[i+1,1]:.2f},', f'LDA Accuracy: {align_acc[i+1,0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if acc.shape[0] > recal_acc.shape[0]:\n",
    "    acc = np.delete(acc,-1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors =  cm.get_cmap('tab20c')\n",
    "c = np.empty((20,4))\n",
    "for i in range(20):\n",
    "    c[i,:] = colors(i*1/20)\n",
    "col = np.empty((7,4))\n",
    "col[0,:] = np.array([0,0,0,1])\n",
    "col[1,:] = c[8,:]\n",
    "col[2,:] = c[0,:]\n",
    "col[3,:] = c[9,:]\n",
    "col[4,:] = c[1,:]\n",
    "col[5,:] = c[10,:]\n",
    "col[6,:] = c[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in range(1,3):\n",
    "    nnVlda = acc[:,mod] - acc[:,0]\n",
    "    annVlda = adapt_acc[:,mod] - acc[:,0]\n",
    "    rnnVlda = recal_acc[:,mod] - acc[:,0]\n",
    "    nnVrlda = acc[:,mod] - recal_acc[:,0]\n",
    "    annVrlda = adapt_acc[:,mod] - adapt_acc[:,0]\n",
    "    rnnVrlda = recal_acc[:,mod] - recal_acc[:,0]\n",
    "    mask = ~np.isnan(annVrlda)\n",
    "    \n",
    "    fig,ax = plt.subplots(1,3,figsize=(16,4))\n",
    "\n",
    "    ax[0].plot(acc[mask,0],'o-',color=col[0,:])\n",
    "    ax[0].plot(recal_acc[mask,0], 'o--',color=col[0,:])\n",
    "    ax[0].plot(acc[mask,mod],'o-',color=col[mod,:])\n",
    "    ax[0].plot(recal_acc[mask,mod], 's-',color=col[mod+2,:])\n",
    "    ax[0].plot(adapt_acc[mask,mod], 'v-',color=col[mod+4,:])\n",
    "    if mod == 1:\n",
    "        ax[0].legend(['LDA', 'r-LDA', 'MLP', 'r-MLP', 'a-MLP', ])\n",
    "    else:\n",
    "        ax[0].legend(['LDA', 'r-LDA', 'CNN', 'r-CNN', 'a-CNN'])\n",
    "    ax[0].set_ylim([0,100])\n",
    "\n",
    "    ax[1].plot(nnVrlda[mask],'o-',color=col[mod,:])\n",
    "    ax[1].plot(rnnVrlda[mask],'s-',color=col[mod+2,:])\n",
    "    ax[1].plot(annVrlda[mask],'v-',color=col[mod+4,:])\n",
    "    if mod == 1:\n",
    "        ax[1].legend(['MLP vs. r-LDA', 'r-MLP vs. r-LDA', 'a-MLP vs. r-LDA'])\n",
    "    else:\n",
    "        ax[1].legend(['CNN vs. r-LDA', 'r-CNN vs. r-LDA', 'a-CNN vs. r-LDA'])\n",
    "    ax[1].axhline(0, ls = '--',color='black')\n",
    "\n",
    "    ax[2].plot(nnVlda[mask],'o-',color=col[mod,:])\n",
    "    ax[2].plot(rnnVlda[mask],'s-',color=col[mod+2,:])\n",
    "    ax[2].plot(annVlda[mask],'v-',color=col[mod+4,:])\n",
    "    if mod == 1:\n",
    "        ax[2].legend(['MLP vs. LDA', 'r-MLP vs. LDA', 'a-MLP vs. LDA'])\n",
    "    else:\n",
    "        ax[2].legend(['CNN vs. LDA', 'r-CNN vs. LDA', 'a-CNN vs. LDA'])\n",
    "    ax[2].axhline(0, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(16,4))\n",
    "x = range(0,acc.shape[0]-2,1)\n",
    "x_skip = range(0,acc.shape[0]-2,2)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[0].plot(x_skip,acc[2::2,i],'o',color=col[i,:], label='_nolegend_')\n",
    "    ax[0].plot(x,acc[2:,i],'-',color=col[i,:])\n",
    "\n",
    "    if i == 0:\n",
    "        ls = 's--'\n",
    "    else:\n",
    "        ls = 's-'\n",
    "    ax[1].plot(x_skip,recal_acc[mask,i], ls,color=col[i,:])\n",
    "\n",
    "    if i > 0:\n",
    "        ax[2].plot(x_skip,adapt_acc[mask,i], 'v-',color=col[i,:])\n",
    "\n",
    "    ax[i].set_ylim([0,100])\n",
    "\n",
    "ax[0].legend(['LDA','MLP','CNN'])\n",
    "ax[1].legend(['r-LDA','r-MLP','r-CNN'])\n",
    "ax[2].legend(['a-MLP','a-CNN'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96e4d54467b05e62951c9fd7929782b99429e3b62c1a3b146d4f3dbf79f907e6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('adapt_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
