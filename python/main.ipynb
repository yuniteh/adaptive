{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gpu import set_gpu\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from adapt.ml.dl_subclass import MLP, MLPprop, CNN, CNNprop, get_train, get_test\n",
    "import adapt.utils.data_utils as prd\n",
    "from adapt.ml.lda import train_lda, eval_lda\n",
    "\n",
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/yteh/Documents/work/necal/home data/TR58/DATA/MAT/'\n",
    "all_files = os.listdir(path)\n",
    "train_file = all_files[0]\n",
    "adapt_file = all_files[1]\n",
    "test_file = all_files[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_params = prd.load_caps_train(path + train_file + '/traindata.mat')\n",
    "train_data = train_data[:,:8,:]\n",
    "train_dof = np.unique(train_params[:,2])\n",
    "key = np.empty(train_dof.shape)\n",
    "for i in range(len(train_dof)):\n",
    "    key[i] = train_params[np.argmax(train_params[:,2] == train_dof[i]),0]\n",
    "\n",
    "train_dof = train_dof[np.argsort(key)]\n",
    "key = np.sort(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.78, Accuracy: 31.92 \n",
      "Epoch 30, Loss: 0.35, Accuracy: 87.24 \n",
      "Epoch 1, Loss: 1.19, Accuracy: 57.32 \n",
      "Epoch 30, Loss: 0.11, Accuracy: 96.14 \n"
     ]
    }
   ],
   "source": [
    "ep = 30\n",
    "n_dof = np.max(train_params[:,0])\n",
    "    \n",
    "# Train NNs\n",
    "mlp = MLP(n_class=n_dof)\n",
    "cnn = CNN(n_class=n_dof)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "train_prop_accuracy = tf.keras.metrics.MeanSquaredError(name='train_prop_accuracy')\n",
    "\n",
    "trainmlp, traincnn, y_train, x_train_mlp, x_train_cnn, x_train_lda, y_train_lda, emg_scale, scaler, x_min, x_max, prop = prd.prep_train_caps(train_data, train_params, prop_b = False)\n",
    "\n",
    "# Train neural networks\n",
    "models = [mlp, cnn]\n",
    "for model in models:\n",
    "    if isinstance(model,CNN):\n",
    "        ds = traincnn\n",
    "    else:\n",
    "        ds = trainmlp\n",
    "    \n",
    "    prop_b = isinstance(model, MLPprop) or isinstance(model, CNNprop)\n",
    "    train_mod = get_train(prop = prop_b)\n",
    "\n",
    "    for epoch in range(ep):\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "\n",
    "        for x, y, y2 in ds:\n",
    "            if prop_b:\n",
    "                train_mod(x, y, model, optimizer, train_loss, train_accuracy, train_prop_accuracy, y2)\n",
    "            else:\n",
    "                train_mod(x, y, model, optimizer, train_loss, train_accuracy)\n",
    "\n",
    "        if epoch == 0 or epoch == ep-1:\n",
    "            print(\n",
    "                f'Epoch {epoch + 1}, '\n",
    "                f'Loss: {train_loss.result():.2f}, '\n",
    "                f'Accuracy: {train_accuracy.result() * 100:.2f} '\n",
    "            )\n",
    "    del train_mod\n",
    "\n",
    "# Train LDA\n",
    "w,c, _, _, _ = train_lda(x_train_lda,y_train_lda)\n",
    "\n",
    "mlp_w = mlp.get_weights()\n",
    "cnn_w = cnn.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set: 20170808_104400 CNN Accuracy: 67.93, MLP Accuracy: 66.37, LDA Accuracy: 56.97\n",
      "oopsie\n",
      "Set: 20170913_053927 CNN Accuracy: 55.70, MLP Accuracy: 40.55, LDA Accuracy: 11.24\n",
      "oopsie\n",
      "Set: 20170913_061042 CNN Accuracy: 78.50, MLP Accuracy: 65.23, LDA Accuracy: 57.00\n",
      "oopsie\n",
      "Set: 20170915_173323 CNN Accuracy: 44.30, MLP Accuracy: 43.73, LDA Accuracy: 17.60\n",
      "oopsie\n",
      "Set: 20170916_161424 CNN Accuracy: 70.85, MLP Accuracy: 61.74, LDA Accuracy: 47.16\n",
      "oopsie\n",
      "Set: 20170923_073346 CNN Accuracy: 54.50, MLP Accuracy: 54.40, LDA Accuracy: 47.74\n",
      "oopsie\n",
      "Set: 20170929_051442 CNN Accuracy: 58.93, MLP Accuracy: 56.95, LDA Accuracy: 48.41\n"
     ]
    }
   ],
   "source": [
    "acc = np.empty((len(all_files)-1,3))\n",
    "train_dof = np.unique(train_params[:,2])\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "for i in range(16,len(all_files)):\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    test_file = all_files[i]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    test_dof = np.unique(test_params[:,2])\n",
    "\n",
    "    test_key = np.empty(test_dof.shape)\n",
    "    for dof_i in range(len(test_dof)):\n",
    "        test_key[dof_i] = test_params[np.argmax(test_params[:,2] == test_dof[dof_i]),0]\n",
    "    \n",
    "    test_dof = test_dof[np.argsort(test_key)]\n",
    "    test_key = np.sort(test_key)\n",
    "\n",
    "    if not(np.all(np.in1d(test_dof,train_dof)) and np.all(np.in1d(train_dof,test_dof))):\n",
    "        if len(test_dof) < len(train_dof):\n",
    "            print('Missing classes')\n",
    "            for key_i in key:\n",
    "                test_params[test_params[:,2] == train_dof[int(key_i-1)],0] = key_i\n",
    "        overlap = ~np.in1d(test_dof, train_dof)\n",
    "        if overlap.any():\n",
    "            print('Removing ' + test_dof[overlap])\n",
    "            for ov_i in range(np.sum(overlap)):\n",
    "                ind = test_params[:,2] == test_dof[overlap][ov_i]\n",
    "                test_params[ind,:] = []\n",
    "                test_data[ind,:] = []\n",
    "\n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=len(train_dof))\n",
    "\n",
    "    # test CNN\n",
    "    test_mod = get_test()\n",
    "    test_mod(x_test_cnn, y_test, cnn, test_loss, test_accuracy)\n",
    "    acc[i-1,0] = test_accuracy.result()*100\n",
    "\n",
    "    # test MLP\n",
    "    del test_mod\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    test_mod = get_test()\n",
    "    test_mod(x_test_mlp, y_test, mlp, test_loss, test_accuracy)\n",
    "    acc[i-1,1] = test_accuracy.result()*100\n",
    "\n",
    "    # test LDA\n",
    "    acc[i-1,2] = eval_lda(w, c, x_lda, y_lda) * 100\n",
    "\n",
    "    print ('Set: ' + test_file, f'CNN Accuracy: {acc[i-1,0]:.2f},', f'MLP Accuracy: {acc[i-1,1]:.2f},', f'LDA Accuracy: {acc[i-1,2]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapt_data, adapt_params = prd.load_caps_train(path + adapt_file + '/traindata.mat')\n",
    "adapt_data = adapt_data[:,:8,:]\n",
    "overlap = np.in1d(np.unique(adapt_params[:,2]), np.unique(train_params[:,2]))\n",
    "overlap.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Accuracy: 36.87\n",
      "MLP Accuracy: 69.24\n",
      "LDA Accuracy: 62.54\n"
     ]
    }
   ],
   "source": [
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(adapt_data, adapt_params, scaler, emg_scale)\n",
    "\n",
    "# test CNN\n",
    "test_mod = get_test()\n",
    "test_mod(x_test_cnn, y_test, cnn, test_loss, test_accuracy)\n",
    "print (f'CNN Accuracy: {test_accuracy.result()*100:.2f}')\n",
    "\n",
    "# test MLP\n",
    "del test_mod\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "\n",
    "test_mod = get_test()\n",
    "test_mod(x_test_mlp, y_test, mlp, test_loss, test_accuracy)\n",
    "print (f'MLP Accuracy: {test_accuracy.result()*100:.2f}')\n",
    "\n",
    "# test LDA\n",
    "acc = eval_lda(w, c, x_lda, y_lda)\n",
    "print (f'LDA Accuracy: {acc*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.68, Accuracy: 76.47 \n",
      "Epoch 5, Loss: 0.37, Accuracy: 85.70 \n",
      "Epoch 1, Loss: 0.61, Accuracy: 81.65 \n",
      "Epoch 5, Loss: 0.21, Accuracy: 92.64 \n"
     ]
    }
   ],
   "source": [
    "ep = 5\n",
    "\n",
    "trainmlp, traincnn, y_train, x_train_mlp, x_train_cnn, x_train_lda, y_train_lda, emg_scale, scaler, x_min, x_max, prop = prd.prep_train_caps(adapt_data, adapt_params, prop_b = False)\n",
    "\n",
    "# Train neural networks\n",
    "models = [mlp, cnn]\n",
    "for model in models:\n",
    "    if isinstance(model,CNN):\n",
    "        ds = traincnn\n",
    "    else:\n",
    "        ds = trainmlp\n",
    "    \n",
    "    prop_b = isinstance(model, MLPprop) or isinstance(model, CNN)\n",
    "    train_mod = get_train(prop = prop_b)\n",
    "\n",
    "    for epoch in range(ep):\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "\n",
    "        for x, y, y2 in ds:\n",
    "            if prop_b:\n",
    "                train_mod(x, y, model, optimizer, train_loss, train_accuracy, train_prop_accuracy, y2)\n",
    "            else:\n",
    "                train_mod(x, y, model, optimizer, train_loss, train_accuracy)\n",
    "\n",
    "        if epoch == 0 or epoch == ep-1:\n",
    "            print(\n",
    "                f'Epoch {epoch + 1}, '\n",
    "                f'Loss: {train_loss.result():.2f}, '\n",
    "                f'Accuracy: {train_accuracy.result() * 100:.2f} '\n",
    "            )\n",
    "    del train_mod\n",
    "\n",
    "# Train LDA\n",
    "w,c, _, _, _ = train_lda(x_train_lda,y_train_lda)\n",
    "\n",
    "mlp_w = mlp.get_weights()\n",
    "cnn_w = cnn.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Accuracy: 36.09\n",
      "MLP Accuracy: 67.80\n",
      "LDA Accuracy: 71.13\n"
     ]
    }
   ],
   "source": [
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "\n",
    "test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "test_data = test_data[:,:8,:].astype('float64')\n",
    "y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale)\n",
    "\n",
    "# test CNN\n",
    "test_mod = get_test()\n",
    "test_mod(x_test_cnn, y_test, cnn, test_loss, test_accuracy)\n",
    "print (f'CNN Accuracy: {test_accuracy.result()*100:.2f}')\n",
    "\n",
    "# test MLP\n",
    "del test_mod\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "\n",
    "test_mod = get_test()\n",
    "test_mod(x_test_mlp, y_test, mlp, test_loss, test_accuracy)\n",
    "print (f'MLP Accuracy: {test_accuracy.result()*100:.2f}')\n",
    "\n",
    "# test LDA\n",
    "acc = eval_lda(w, c, x_lda, y_lda)\n",
    "print (f'LDA Accuracy: {acc*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96e4d54467b05e62951c9fd7929782b99429e3b62c1a3b146d4f3dbf79f907e6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('adapt_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
