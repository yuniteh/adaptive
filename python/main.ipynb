{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gpu import set_gpu\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from adapt.ml.dl_subclass import MLP, MLPprop, CNN, CNNprop, get_train, get_test\n",
    "import adapt.utils.data_utils as prd\n",
    "from adapt.ml.lda import train_lda, eval_lda\n",
    "import adapt.loop as lp\n",
    "\n",
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/yteh/Documents/work/necal/home data/TR58/DATA/MAT/'\n",
    "all_files = os.listdir(path)\n",
    "train_file = all_files[0]\n",
    "adapt_file = all_files[1]\n",
    "test_file = all_files[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_params = prd.load_caps_train(path + train_file + '/traindata.mat')\n",
    "train_data = train_data[:,:8,:]\n",
    "\n",
    "train_dof = np.unique(train_params[:,2])\n",
    "key = np.empty(train_dof.shape)\n",
    "for i in range(len(train_dof)):\n",
    "    key[i] = train_params[np.argmax(train_params[:,2] == train_dof[i]),0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,  Loss: 1.60,  Accuracy: 42.65 \n",
      "Epoch 30,  Loss: 0.34,  Accuracy: 87.23 \n",
      "Epoch 1,  Loss: 1.21,  Accuracy: 57.54 \n",
      "Epoch 30,  Loss: 0.11,  Accuracy: 96.23 \n"
     ]
    }
   ],
   "source": [
    "# Initial training\n",
    "ep = 30\n",
    "n_dof = len(train_dof)\n",
    "\n",
    "trainmlp, traincnn, y_train, x_train_mlp, x_train_cnn, x_train_lda, y_train_lda, emg_scale, scaler, _, _, _ = prd.prep_train_caps(train_data, train_params, prop_b = False)\n",
    "mlp, cnn, w, c = lp.train_models(traincnn, trainmlp, x_train_lda, y_train_lda, n_dof, ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set: 20170730_054913 CNN Accuracy: 68.18, MLP Accuracy: 72.69, LDA Accuracy: 62.54\n",
      "Set: 20170730_055812 CNN Accuracy: 68.10, MLP Accuracy: 71.26, LDA Accuracy: 71.13\n",
      "Set: 20170730_060537 CNN Accuracy: 64.52, MLP Accuracy: 66.88, LDA Accuracy: 66.16\n",
      "Set: 20170730_123937 CNN Accuracy: 67.00, MLP Accuracy: 67.59, LDA Accuracy: 65.40\n",
      "Set: 20170731_123147 CNN Accuracy: 63.72, MLP Accuracy: 68.98, LDA Accuracy: 52.47\n",
      "Set: 20170801_053500 CNN Accuracy: 62.37, MLP Accuracy: 62.03, LDA Accuracy: 55.88\n",
      "Set: 20170801_054938 CNN Accuracy: 58.95, MLP Accuracy: 63.67, LDA Accuracy: 51.92\n",
      "Set: 20170801_065547 CNN Accuracy: 73.66, MLP Accuracy: 71.22, LDA Accuracy: 65.23\n",
      "Set: 20170802_050945 CNN Accuracy: 64.90, MLP Accuracy: 66.96, LDA Accuracy: 55.58\n",
      "Set: 20170802_051732 CNN Accuracy: 62.41, MLP Accuracy: 63.55, LDA Accuracy: 62.41\n",
      "Set: 20170802_052140 CNN Accuracy: 63.46, MLP Accuracy: 63.51, LDA Accuracy: 56.60\n",
      "Set: 20170807_153152 CNN Accuracy: 61.31, MLP Accuracy: 65.53, LDA Accuracy: 53.06\n",
      "Set: 20170807_153559 CNN Accuracy: 56.17, MLP Accuracy: 60.89, LDA Accuracy: 49.68\n",
      "Set: 20170808_054353 CNN Accuracy: 67.47, MLP Accuracy: 71.64, LDA Accuracy: 54.24\n",
      "Set: 20170808_063929 CNN Accuracy: 60.56, MLP Accuracy: 62.71, LDA Accuracy: 52.84\n",
      "Set: 20170808_104400 CNN Accuracy: 66.33, MLP Accuracy: 67.76, LDA Accuracy: 56.97\n",
      "Missing classes\n",
      "Set: 20170913_053927 CNN Accuracy: 51.12, MLP Accuracy: 43.10, LDA Accuracy: 11.24\n",
      "Missing classes\n",
      "Set: 20170913_061042 CNN Accuracy: 72.10, MLP Accuracy: 61.48, LDA Accuracy: 57.00\n",
      "Missing classes\n",
      "Set: 20170915_173323 CNN Accuracy: 40.29, MLP Accuracy: 40.92, LDA Accuracy: 17.60\n",
      "Missing classes\n",
      "Set: 20170916_161424 CNN Accuracy: 62.05, MLP Accuracy: 57.99, LDA Accuracy: 47.16\n",
      "Missing classes\n",
      "Set: 20170923_073346 CNN Accuracy: 49.77, MLP Accuracy: 43.88, LDA Accuracy: 47.74\n",
      "Missing classes\n",
      "Set: 20170929_051442 CNN Accuracy: 48.98, MLP Accuracy: 54.24, LDA Accuracy: 48.41\n"
     ]
    }
   ],
   "source": [
    "# Test all controllers without recalibration or adaptation\n",
    "acc = np.empty((len(all_files)-1,3))\n",
    "\n",
    "for i in range(1,len(all_files)):\n",
    "    # load data\n",
    "    test_file = all_files[i]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data,test_params,train_dof,key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=len(train_dof))\n",
    "    acc[i-1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, w, c)\n",
    "\n",
    "    print ('Set: ' + test_file, f'CNN Accuracy: {acc[i-1,0]:.2f},', f'MLP Accuracy: {acc[i-1,1]:.2f},', f'LDA Accuracy: {acc[i-1,2]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,  Loss: 1.57,  Accuracy: 46.49 \n",
      "Epoch 30,  Loss: 0.35,  Accuracy: 86.66 \n",
      "Epoch 1,  Loss: 1.26,  Accuracy: 55.03 \n",
      "Epoch 30,  Loss: 0.13,  Accuracy: 95.35 \n",
      "Recal: 20170728_103239, Test: 20170730_054913 , CNN Accuracy: 68.18, MLP Accuracy: 72.69, LDA Accuracy: 62.54\n",
      "Epoch 1,  Loss: 1.49,  Accuracy: 49.29 \n",
      "Epoch 30,  Loss: 0.21,  Accuracy: 92.49 \n",
      "Epoch 1,  Loss: 1.23,  Accuracy: 57.15 \n",
      "Epoch 30,  Loss: 0.07,  Accuracy: 97.58 \n",
      "Recal: 20170730_055812, Test: 20170730_060537 , CNN Accuracy: 64.52, MLP Accuracy: 66.88, LDA Accuracy: 66.16\n",
      "Epoch 1,  Loss: 1.52,  Accuracy: 47.56 \n",
      "Epoch 30,  Loss: 0.15,  Accuracy: 94.87 \n",
      "Epoch 1,  Loss: 1.01,  Accuracy: 67.85 \n",
      "Epoch 30,  Loss: 0.03,  Accuracy: 98.86 \n",
      "Recal: 20170730_123937, Test: 20170731_123147 , CNN Accuracy: 63.72, MLP Accuracy: 68.98, LDA Accuracy: 52.47\n",
      "Epoch 1,  Loss: 1.82,  Accuracy: 29.84 \n",
      "Epoch 30,  Loss: 0.35,  Accuracy: 87.21 \n",
      "Epoch 1,  Loss: 1.37,  Accuracy: 53.84 \n",
      "Epoch 30,  Loss: 0.14,  Accuracy: 95.36 \n",
      "Recal: 20170801_053500, Test: 20170801_054938 , CNN Accuracy: 58.95, MLP Accuracy: 63.67, LDA Accuracy: 51.92\n",
      "Epoch 1,  Loss: 1.60,  Accuracy: 43.90 \n",
      "Epoch 30,  Loss: 0.24,  Accuracy: 91.46 \n",
      "Epoch 1,  Loss: 1.19,  Accuracy: 60.42 \n",
      "Epoch 30,  Loss: 0.04,  Accuracy: 98.82 \n",
      "Recal: 20170801_065547, Test: 20170802_050945 , CNN Accuracy: 64.90, MLP Accuracy: 66.96, LDA Accuracy: 55.58\n",
      "Epoch 1,  Loss: 1.55,  Accuracy: 45.20 \n",
      "Epoch 30,  Loss: 0.19,  Accuracy: 92.88 \n",
      "Epoch 1,  Loss: 1.05,  Accuracy: 66.15 \n",
      "Epoch 30,  Loss: 0.05,  Accuracy: 98.37 \n",
      "Recal: 20170802_051732, Test: 20170802_052140 , CNN Accuracy: 63.46, MLP Accuracy: 63.51, LDA Accuracy: 56.60\n",
      "Epoch 1,  Loss: 1.59,  Accuracy: 44.70 \n",
      "Epoch 30,  Loss: 0.20,  Accuracy: 92.44 \n",
      "Epoch 1,  Loss: 1.18,  Accuracy: 59.00 \n",
      "Epoch 30,  Loss: 0.05,  Accuracy: 98.16 \n",
      "Recal: 20170807_153152, Test: 20170807_153559 , CNN Accuracy: 56.17, MLP Accuracy: 60.89, LDA Accuracy: 49.68\n",
      "Epoch 1,  Loss: 1.56,  Accuracy: 42.94 \n",
      "Epoch 30,  Loss: 0.23,  Accuracy: 90.82 \n",
      "Epoch 1,  Loss: 1.00,  Accuracy: 66.42 \n",
      "Epoch 30,  Loss: 0.07,  Accuracy: 97.39 \n",
      "Recal: 20170808_054353, Test: 20170808_063929 , CNN Accuracy: 60.56, MLP Accuracy: 62.71, LDA Accuracy: 52.84\n",
      "Epoch 1,  Loss: 1.60,  Accuracy: 44.60 \n",
      "Epoch 30,  Loss: 0.19,  Accuracy: 93.02 \n",
      "Epoch 1,  Loss: 1.09,  Accuracy: 61.63 \n",
      "Epoch 30,  Loss: 0.07,  Accuracy: 97.66 \n",
      "Missing classes\n",
      "Recal: 20170808_104400, Test: 20170913_053927 , CNN Accuracy: 51.12, MLP Accuracy: 43.10, LDA Accuracy: 11.24\n",
      "Epoch 1,  Loss: 1.28,  Accuracy: 56.85 \n",
      "Epoch 30,  Loss: 0.08,  Accuracy: 97.07 \n",
      "Epoch 1,  Loss: 0.86,  Accuracy: 74.25 \n",
      "Epoch 30,  Loss: 0.01,  Accuracy: 99.70 \n",
      "Recal: 20170913_061042, Test: 20170915_173323 , CNN Accuracy: 40.29, MLP Accuracy: 40.92, LDA Accuracy: 17.60\n",
      "Epoch 1,  Loss: 1.40,  Accuracy: 53.84 \n",
      "Epoch 30,  Loss: 0.22,  Accuracy: 92.47 \n",
      "Epoch 1,  Loss: 0.99,  Accuracy: 68.34 \n",
      "Epoch 30,  Loss: 0.04,  Accuracy: 98.82 \n",
      "Recal: 20170916_161424, Test: 20170923_073346 , CNN Accuracy: 49.77, MLP Accuracy: 43.88, LDA Accuracy: 47.74\n"
     ]
    }
   ],
   "source": [
    "# Test all controllers with recalibration\n",
    "ep = 30\n",
    "# Remove extra file if odd number of files\n",
    "if len(all_files)%2 == 0:\n",
    "    all_files[-1] = []\n",
    "recal_acc = np.empty((len(all_files)-1,3))\n",
    "recal_acc[:] = np.nan\n",
    "\n",
    "for i in range(1,len(all_files)-1,2):\n",
    "    # load recalibration data\n",
    "    recal_file = all_files[i]\n",
    "    recal_data, recal_params = prd.load_caps_train(path + recal_file + '/traindata.mat')\n",
    "    recal_data = recal_data[:,:8,:]\n",
    "\n",
    "    recal_dof = np.unique(recal_params[:,2])\n",
    "    recal_key = np.empty(recal_dof.shape)\n",
    "    for dof_i in range(len(recal_dof)):\n",
    "        recal_key[dof_i] = recal_params[np.argmax(recal_params[:,2] == recal_dof[dof_i]),0]\n",
    "    n_dof = len(recal_dof)\n",
    "    \n",
    "    recalmlp, recalcnn, _, _, _, x_train_lda, y_train_lda, emg_scale, scaler, _, _, _ = prd.prep_train_caps(recal_data, recal_params, prop_b = False)\n",
    "    mlp, cnn, w, c = lp.train_models(recalcnn, recalmlp, x_train_lda, y_train_lda, n_dof, ep)\n",
    "    \n",
    "    # load data\n",
    "    test_file = all_files[i+1]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data,test_params,recal_dof,recal_key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=n_dof)\n",
    "    recal_acc[i+1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, w, c)\n",
    "\n",
    "    print ('Recal: ' + recal_file + ', Test: ' + test_file, f', CNN Accuracy: {recal_acc[i+1,0]:.2f},', f'MLP Accuracy: {recal_acc[i+1,1]:.2f},', f'LDA Accuracy: {recal_acc[i+1,2]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all controllers with adaptation\n",
    "ep = 5\n",
    "# Remove extra file if odd number of files\n",
    "if len(all_files)%2 == 0:\n",
    "    all_files[-1] = []\n",
    "adapt_acc = np.empty((len(all_files)-1,3))\n",
    "adapt_acc[:] = np.nan\n",
    "\n",
    "for i in range(1,len(all_files)-1,2):\n",
    "    # load recalibration data\n",
    "    adapt_file = all_files[i]\n",
    "    adapt_data, adapt_params = prd.load_caps_train(path + adapt_file + '/traindata.mat')\n",
    "    adapt_data = adapt_data[:,:8,:]\n",
    "\n",
    "    # check class labels\n",
    "    adapt_data, adapt_params = lp.check_labels(adapt_data, adapt_params, train_dof, key)\n",
    "    \n",
    "    adaptmlp, adaptcnn, _, _, _, x_train_lda, y_train_lda, emg_scale, scaler, _, _, _ = prd.prep_train_caps(adapt_data, adapt_params, prop_b = False)\n",
    "    mlp, cnn, w, c = lp.train_models(adaptcnn, adaptmlp, x_train_lda, y_train_lda, n_dof, ep, mlp, cnn)\n",
    "    \n",
    "    # load data\n",
    "    test_file = all_files[i+1]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data, test_params, train_dof, key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=n_dof)\n",
    "    adapt_acc[i+1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, w, c)\n",
    "\n",
    "    print ('Recal: ' + adapt_file + ', Test: ' + test_file, f', CNN Accuracy: {adapt_acc[i+1,0]:.2f},', f'MLP Accuracy: {adapt_acc[i+1,1]:.2f},', f'LDA Accuracy: {adapt_acc[i+1,2]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(all_files)):\n",
    "    # load data\n",
    "    test_file = all_files[i]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data,test_params,train_dof,key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=len(train_dof))\n",
    "    acc[i-1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, w, c)\n",
    "\n",
    "    print ('Set: ' + test_file, f'CNN Accuracy: {acc[i-1,0]:.2f},', f'MLP Accuracy: {acc[i-1,1]:.2f},', f'LDA Accuracy: {acc[i-1,2]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Accuracy: 36.87\n",
      "MLP Accuracy: 69.24\n",
      "LDA Accuracy: 62.54\n"
     ]
    }
   ],
   "source": [
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(adapt_data, adapt_params, scaler, emg_scale)\n",
    "\n",
    "# test CNN\n",
    "test_mod = get_test()\n",
    "test_mod(x_test_cnn, y_test, cnn, test_loss, test_accuracy)\n",
    "print (f'CNN Accuracy: {test_accuracy.result()*100:.2f}')\n",
    "\n",
    "# test MLP\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "\n",
    "test_mod = get_test()\n",
    "test_mod(x_test_mlp, y_test, mlp, test_loss, test_accuracy)\n",
    "print (f'MLP Accuracy: {test_accuracy.result()*100:.2f}')\n",
    "\n",
    "# test LDA\n",
    "acc = eval_lda(w, c, x_lda, y_lda)\n",
    "print (f'LDA Accuracy: {acc*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.68, Accuracy: 76.47 \n",
      "Epoch 5, Loss: 0.37, Accuracy: 85.70 \n",
      "Epoch 1, Loss: 0.61, Accuracy: 81.65 \n",
      "Epoch 5, Loss: 0.21, Accuracy: 92.64 \n"
     ]
    }
   ],
   "source": [
    "ep = 5\n",
    "\n",
    "trainmlp, traincnn, y_train, x_train_mlp, x_train_cnn, x_train_lda, y_train_lda, emg_scale, scaler, x_min, x_max, prop = prd.prep_train_caps(adapt_data, adapt_params, prop_b = False)\n",
    "\n",
    "# Train neural networks\n",
    "models = [mlp, cnn]\n",
    "for model in models:\n",
    "    if isinstance(model,CNN):\n",
    "        ds = traincnn\n",
    "    else:\n",
    "        ds = trainmlp\n",
    "    \n",
    "    prop_b = isinstance(model, MLPprop) or isinstance(model, CNN)\n",
    "    train_mod = get_train(prop = prop_b)\n",
    "\n",
    "    for epoch in range(ep):\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "\n",
    "        for x, y, y2 in ds:\n",
    "            if prop_b:\n",
    "                train_mod(x, y, model, optimizer, train_loss, train_accuracy, train_prop_accuracy, y2)\n",
    "            else:\n",
    "                train_mod(x, y, model, optimizer, train_loss, train_accuracy)\n",
    "\n",
    "        if epoch == 0 or epoch == ep-1:\n",
    "            print(\n",
    "                f'Epoch {epoch + 1}, '\n",
    "                f'Loss: {train_loss.result():.2f}, '\n",
    "                f'Accuracy: {train_accuracy.result() * 100:.2f} '\n",
    "            )\n",
    "    del train_mod\n",
    "\n",
    "# Train LDA\n",
    "w,c, _, _, _ = train_lda(x_train_lda,y_train_lda)\n",
    "\n",
    "mlp_w = mlp.get_weights()\n",
    "cnn_w = cnn.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Accuracy: 36.09\n",
      "MLP Accuracy: 67.80\n",
      "LDA Accuracy: 71.13\n"
     ]
    }
   ],
   "source": [
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "\n",
    "test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "test_data = test_data[:,:8,:].astype('float64')\n",
    "y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale)\n",
    "\n",
    "# test CNN\n",
    "test_mod = get_test()\n",
    "test_mod(x_test_cnn, y_test, cnn, test_loss, test_accuracy)\n",
    "print (f'CNN Accuracy: {test_accuracy.result()*100:.2f}')\n",
    "\n",
    "# test MLP\n",
    "del test_mod\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "\n",
    "test_mod = get_test()\n",
    "test_mod(x_test_mlp, y_test, mlp, test_loss, test_accuracy)\n",
    "print (f'MLP Accuracy: {test_accuracy.result()*100:.2f}')\n",
    "\n",
    "# test LDA\n",
    "acc = eval_lda(w, c, x_lda, y_lda)\n",
    "print (f'LDA Accuracy: {acc*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96e4d54467b05e62951c9fd7929782b99429e3b62c1a3b146d4f3dbf79f907e6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('adapt_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
