{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from gpu import set_gpu\n",
    "import numpy as np\n",
    "import os\n",
    "import adapt.utils.data_utils as prd\n",
    "import adapt.loop as lp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import adapt.ml.dl_subclass as dl\n",
    "import copy as cp\n",
    "\n",
    "set_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/yteh/Documents/work/necal/home data/TR58/DATA/MAT/'\n",
    "all_files = os.listdir(path)\n",
    "train_file = all_files[0]\n",
    "train_file2 = all_files[1]\n",
    "ft= 'feat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = np.delete(all_files,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_params = prd.load_caps_train(path + train_file + '/traindata.mat')\n",
    "train_data = train_data[:,:8,:]\n",
    "\n",
    "train_dof = np.unique(train_params[:,2])\n",
    "key = np.empty(train_dof.shape)\n",
    "for i in range(len(train_dof)):\n",
    "    key[i] = train_params[np.argmax(train_params[:,2] == train_dof[i]),0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2, train_params2 = prd.load_caps_train(path + train_file2 + '/traindata.mat')\n",
    "train_data2 = train_data2[:,:8,:]\n",
    "train_data = np.vstack((train_data,train_data2))\n",
    "train_params = np.vstack((train_params,train_params2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep initial training data\n",
    "ep = 30\n",
    "n_dof = len(train_dof)\n",
    "\n",
    "trainmlp_0, traincnn_0, y_train_0, x_train_mlp_0, x_train_cnn_0, x_train_lda_0, y_train_lda_0, emg_scale, scaler, _, _, _ = prd.prep_train_caps(train_data, train_params, prop_b = False, batch_size=64,ft=ft, noise=True)\n",
    "y_test_0, x_test_mlp_0, x_test_cnn_0, x_lda_0, y_lda_0 = prd.prep_test_caps(train_data, train_params, scaler, emg_scale, num_classes=len(train_dof),ft=ft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial training\n",
    "mlp, cnn, w, c = lp.train_models(traincnn_0, trainmlp_0, x_train_lda_0, y_train_lda_0, n_dof, ep=30)\n",
    "mlp_0 = mlp.get_weights()\n",
    "cnn_0 = cnn.get_weights()\n",
    "w_0 = cp.deepcopy(w)\n",
    "c_0 = cp.deepcopy(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set: 20170728_103239 CNN Accuracy: 95.32, MLP Accuracy: 84.11, LDA Accuracy: 74.88\n",
      "Set: 20170730_054913 CNN Accuracy: 72.65, MLP Accuracy: 71.68, LDA Accuracy: 62.54\n",
      "Set: 20170730_055812 CNN Accuracy: 72.90, MLP Accuracy: 69.91, LDA Accuracy: 71.13\n",
      "Set: 20170730_060537 CNN Accuracy: 68.14, MLP Accuracy: 65.61, LDA Accuracy: 66.16\n",
      "Set: 20170730_123937 CNN Accuracy: 70.46, MLP Accuracy: 67.72, LDA Accuracy: 65.40\n",
      "Set: 20170731_123147 CNN Accuracy: 64.05, MLP Accuracy: 64.81, LDA Accuracy: 52.47\n",
      "Set: 20170801_053500 CNN Accuracy: 63.97, MLP Accuracy: 62.33, LDA Accuracy: 55.88\n",
      "Set: 20170801_054938 CNN Accuracy: 60.51, MLP Accuracy: 59.33, LDA Accuracy: 51.92\n",
      "Set: 20170801_065547 CNN Accuracy: 71.64, MLP Accuracy: 69.41, LDA Accuracy: 65.23\n",
      "Set: 20170802_050945 CNN Accuracy: 66.79, MLP Accuracy: 66.58, LDA Accuracy: 55.58\n",
      "Set: 20170802_051732 CNN Accuracy: 64.73, MLP Accuracy: 63.80, LDA Accuracy: 62.41\n",
      "Set: 20170802_052140 CNN Accuracy: 64.60, MLP Accuracy: 65.44, LDA Accuracy: 56.60\n",
      "Set: 20170807_153152 CNN Accuracy: 63.59, MLP Accuracy: 64.31, LDA Accuracy: 53.06\n",
      "Set: 20170807_153559 CNN Accuracy: 56.72, MLP Accuracy: 59.00, LDA Accuracy: 49.68\n",
      "Set: 20170808_054353 CNN Accuracy: 69.07, MLP Accuracy: 68.18, LDA Accuracy: 54.24\n",
      "Set: 20170808_063929 CNN Accuracy: 62.58, MLP Accuracy: 60.18, LDA Accuracy: 52.84\n",
      "Set: 20170808_104400 CNN Accuracy: 70.21, MLP Accuracy: 67.80, LDA Accuracy: 56.97\n",
      "Missing classes\n",
      "Set: 20170913_053927 CNN Accuracy: 53.31, MLP Accuracy: 58.09, LDA Accuracy: 11.24\n",
      "Missing classes\n",
      "Set: 20170913_061042 CNN Accuracy: 79.18, MLP Accuracy: 67.05, LDA Accuracy: 57.00\n",
      "Missing classes\n",
      "Set: 20170915_173323 CNN Accuracy: 45.39, MLP Accuracy: 53.05, LDA Accuracy: 17.60\n",
      "Missing classes\n",
      "Set: 20170916_161424 CNN Accuracy: 70.85, MLP Accuracy: 62.78, LDA Accuracy: 47.16\n",
      "Missing classes\n",
      "Set: 20170923_073346 CNN Accuracy: 59.45, MLP Accuracy: 60.18, LDA Accuracy: 47.74\n",
      "Missing classes\n",
      "Set: 20170929_051442 CNN Accuracy: 63.66, MLP Accuracy: 61.79, LDA Accuracy: 48.41\n"
     ]
    }
   ],
   "source": [
    "# Test all controllers without recalibration or adaptation\n",
    "acc = np.empty((len(all_files),4))\n",
    "\n",
    "for i in range(0,len(all_files)):\n",
    "    # load data\n",
    "    test_file = all_files[i]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:]\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data,test_params,train_dof,key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=len(train_dof),ft=ft)\n",
    "    acc[i,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, [w, c])\n",
    "    print ('Set: ' + test_file, f'CNN Accuracy: {acc[i,2]:.2f},', f'MLP Accuracy: {acc[i,1]:.2f},', f'LDA Accuracy: {acc[i,0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial train acc: 0.0996, val acc 0: 0.0952\n"
     ]
    }
   ],
   "source": [
    "# Test all controllers with ewc\n",
    "ep = 30\n",
    "# Remove extra file if odd number of files\n",
    "if len(all_files)%2 == 0:\n",
    "    all_files = np.delete(all_files,-1)\n",
    "ewc_acc = np.empty((len(all_files),4))\n",
    "ewc_acc[:] = np.nan\n",
    "rec_acc = np.empty((len(all_files),4))\n",
    "rec_acc[:] = np.nan\n",
    "\n",
    "n_dof = len(train_dof)\n",
    "\n",
    "cnn.set_weights(cnn_0)\n",
    "mlp.set_weights(mlp_0)\n",
    "\n",
    "ewc = dl.EWC()\n",
    "# ewc(x_train_mlp_0[:1,...])\n",
    "ewc(x_train_cnn_0[:1,...])\n",
    "loss, fish_loss = lp.train_task(ewc, ep, 1, x_train_cnn_0,y_train_0, [x_test_cnn_0],[y_test_0], lams=[0])\n",
    "x_train_ewc_cnn = cp.deepcopy(x_train_cnn_0)\n",
    "y_train_ewc = cp.deepcopy(y_train_0)\n",
    "x_test_ewc_0 = cp.deepcopy(x_test_cnn_0)\n",
    "y_test_ewc_0 = cp.deepcopy(y_test_0)\n",
    "\n",
    "# loss, fish_loss = lp.train_task(ewc, ep, 1, x_train_mlp_0,y_train_0, [x_test_mlp_0],[y_test_0], lams=[0])\n",
    "# x_train_ewc = cp.deepcopy(x_train_mlp_0)\n",
    "# y_train_ewc = cp.deepcopy(y_train_0)\n",
    "# x_test_ewc_0 = cp.deepcopy(x_test_mlp_0)\n",
    "# y_test_ewc_0 = cp.deepcopy(y_test_0)\n",
    "\n",
    "ewc_acc[0,:] = lp.test_models(x_test_cnn_0, x_test_mlp_0, x_lda_0, y_test_0, y_lda_0, cnn, mlp, [w_0, c_0], ewc)\n",
    "\n",
    "for i in range(1,len(all_files)-1,2):\n",
    "    # load recalibration data\n",
    "    ewc_file = all_files[i]\n",
    "    ewc_data, ewc_params = prd.load_caps_train(path + ewc_file + '/traindata.mat')\n",
    "    ewc_data = ewc_data[:,:8,:]\n",
    "\n",
    "    ewc.compute_fisher(x_train_ewc_cnn, y_train_ewc, num_samples=200, plot_diffs=False) # use validation set for Fisher computation\n",
    "    ewc.star()\n",
    "\n",
    "    # check class labels\n",
    "    ewc_data, ewc_params = lp.check_labels(ewc_data, ewc_params, train_dof, key)\n",
    "    \n",
    "    ewcmlp, ewccnn, y_train_ewc, x_train_ewc, x_train_ewc_cnn, x_train_lda, y_train_lda, _, _, _, _, _ = prd.prep_train_caps(ewc_data, ewc_params, prop_b = False, num_classes=n_dof, batch_size=64, noise=True, scaler=scaler, emg_scale=emg_scale,ft=ft)\n",
    "    y_test_ewc, x_test_ewc, x_test_ewc_cnn, _, _ = prd.prep_test_caps(ewc_data, ewc_params, scaler, emg_scale, num_classes=n_dof,ft=ft)\n",
    "\n",
    "    loss, fish_loss = lp.train_task(ewc, 30, 1, x_train_ewc_cnn,y_train_ewc, [x_test_ewc_0, x_test_ewc_cnn], [y_test_ewc_0, y_test_ewc], lams=[15])#,15,50])\n",
    "    # loss, fish_loss = lp.train_task(ewc, 30, 1, x_train_ewc,y_train_ewc, [x_test_ewc_0, x_test_ewc], [y_test_ewc_0, y_test_ewc], lams=[15])#,15,50])\n",
    "    mlp, cnn, w, c = lp.train_models(ewccnn, ewcmlp, x_train_lda, y_train_lda, n_dof, 5, mlp, cnn)\n",
    "    mlp_r, cnn_r, _, _ = lp.train_models(ewccnn, ewcmlp, n_dof=n_dof, ep=30)\n",
    "\n",
    "    # load test data\n",
    "    test_file = all_files[i+1]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:]\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data, test_params, train_dof, key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=n_dof,ft=ft)\n",
    "    ewc_acc[i+1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, [w,c],ewc)\n",
    "    rec_acc[i+1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn_r, mlp_r)\n",
    "\n",
    "    x_test_ewc_0 = cp.deepcopy(x_test_ewc_cnn)\n",
    "    y_test_ewc_0 = cp.deepcopy(y_test_ewc)\n",
    "\n",
    "    print ('EWC: ' + ewc_file + ', Test: ' + test_file + ',', f'EWC Accuracy: {ewc_acc[i+1,3]:.2f},', f'a-CNN Accuracy: {ewc_acc[i+1,2]:.2f},', f'a-MLP Accuracy: {ewc_acc[i+1,1]:.2f},',  f'r-CNN Accuracy: {rec_acc[i+1,2]:.2f},', f'r-MLP Accuracy: {rec_acc[i+1,1]:.2f},', f'r-LDA Accuracy: {ewc_acc[i+1,0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all controllers with adaptation\n",
    "ep = 15\n",
    "# Remove extra file if odd number of files\n",
    "if len(all_files)%2 == 0:\n",
    "    all_files = np.delete(all_files,-1)\n",
    "align_acc = np.empty((len(all_files),3))\n",
    "align_acc[:] = np.nan\n",
    "n_dof = len(train_dof)\n",
    "\n",
    "for i in range(1,len(all_files)-1,2):\n",
    "    # load recalibration data\n",
    "    align_file = all_files[i]\n",
    "    align_data, align_params = prd.load_caps_train(path + align_file + '/traindata.mat')\n",
    "    align_data = align_data[:,:8,:]\n",
    "\n",
    "    # check class labels\n",
    "    align_data, align_params = lp.check_labels(align_data, align_params, train_dof, key)\n",
    "    \n",
    "    alignmlp, aligncnn, _, _, _, x_train_lda, y_train_lda, emg_scale, scaler, _, _, _ = prd.prep_train_caps(align_data, align_params, prop_b = False, num_classes=n_dof, batch_size=64, noise=True, scaler=scaler, emg_scale=emg_scale,ft=ft)\n",
    "    mlp, cnn, mlp_ali, cnn_ali, w, c = lp.train_models(aligncnn, alignmlp, x_train_lda, y_train_lda, n_dof, ep, mlp, cnn, align=True)\n",
    "    \n",
    "    # load data\n",
    "    test_file = all_files[i+1]\n",
    "    test_data, test_params = prd.load_caps_train(path + test_file + '/traindata.mat')\n",
    "    test_data = test_data[:,:8,:].astype('float64')\n",
    "    \n",
    "    # check class labels\n",
    "    test_data, test_params = lp.check_labels(test_data, test_params, train_dof, key)\n",
    "\n",
    "    # test \n",
    "    y_test, x_test_mlp, x_test_cnn, x_lda, y_lda = prd.prep_test_caps(test_data, test_params, scaler, emg_scale, num_classes=n_dof,ft=ft)\n",
    "    align_acc[i+1,:] = lp.test_models(x_test_cnn, x_test_mlp, x_lda, y_test, y_lda, cnn, mlp, [w, c], cnn_align=cnn_ali, mlp_align=mlp_ali)\n",
    "\n",
    "    print ('Align: ' + align_file + ', Test: ' + test_file, f', CNN Accuracy: {align_acc[i+1,2]:.2f},', f'MLP Accuracy: {align_acc[i+1,1]:.2f},', f'LDA Accuracy: {align_acc[i+1,0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if acc.shape[0] > recal_acc.shape[0]:\n",
    "    acc = np.delete(acc,-1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors =  cm.get_cmap('tab20c')\n",
    "c = np.empty((20,4))\n",
    "for i in range(20):\n",
    "    c[i,:] = colors(i*1/20)\n",
    "col = np.empty((7,4))\n",
    "col[0,:] = np.array([0,0,0,1])\n",
    "col[1,:] = c[8,:]\n",
    "col[2,:] = c[0,:]\n",
    "col[3,:] = c[9,:]\n",
    "col[4,:] = c[1,:]\n",
    "col[5,:] = c[10,:]\n",
    "col[6,:] = c[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in range(1,3):\n",
    "    nnVlda = acc[:,mod] - acc[:,0]\n",
    "    annVlda = adapt_acc[:,mod] - acc[:,0]\n",
    "    rnnVlda = recal_acc[:,mod] - acc[:,0]\n",
    "    nnVrlda = acc[:,mod] - recal_acc[:,0]\n",
    "    annVrlda = adapt_acc[:,mod] - adapt_acc[:,0]\n",
    "    rnnVrlda = recal_acc[:,mod] - recal_acc[:,0]\n",
    "    mask = ~np.isnan(annVrlda)\n",
    "    \n",
    "    fig,ax = plt.subplots(1,3,figsize=(16,4))\n",
    "\n",
    "    ax[0].plot(acc[mask,0],'o-',color=col[0,:])\n",
    "    ax[0].plot(recal_acc[mask,0], 'o--',color=col[0,:])\n",
    "    ax[0].plot(acc[mask,mod],'o-',color=col[mod,:])\n",
    "    ax[0].plot(recal_acc[mask,mod], 's-',color=col[mod+2,:])\n",
    "    ax[0].plot(adapt_acc[mask,mod], 'v-',color=col[mod+4,:])\n",
    "    if mod == 1:\n",
    "        ax[0].legend(['LDA', 'r-LDA', 'MLP', 'r-MLP', 'a-MLP', ])\n",
    "    else:\n",
    "        ax[0].legend(['LDA', 'r-LDA', 'CNN', 'r-CNN', 'a-CNN'])\n",
    "    ax[0].set_ylim([0,100])\n",
    "\n",
    "    ax[1].plot(nnVrlda[mask],'o-',color=col[mod,:])\n",
    "    ax[1].plot(rnnVrlda[mask],'s-',color=col[mod+2,:])\n",
    "    ax[1].plot(annVrlda[mask],'v-',color=col[mod+4,:])\n",
    "    if mod == 1:\n",
    "        ax[1].legend(['MLP vs. r-LDA', 'r-MLP vs. r-LDA', 'a-MLP vs. r-LDA'])\n",
    "    else:\n",
    "        ax[1].legend(['CNN vs. r-LDA', 'r-CNN vs. r-LDA', 'a-CNN vs. r-LDA'])\n",
    "    ax[1].axhline(0, ls = '--',color='black')\n",
    "\n",
    "    ax[2].plot(nnVlda[mask],'o-',color=col[mod,:])\n",
    "    ax[2].plot(rnnVlda[mask],'s-',color=col[mod+2,:])\n",
    "    ax[2].plot(annVlda[mask],'v-',color=col[mod+4,:])\n",
    "    if mod == 1:\n",
    "        ax[2].legend(['MLP vs. LDA', 'r-MLP vs. LDA', 'a-MLP vs. LDA'])\n",
    "    else:\n",
    "        ax[2].legend(['CNN vs. LDA', 'r-CNN vs. LDA', 'a-CNN vs. LDA'])\n",
    "    ax[2].axhline(0, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(16,4))\n",
    "x = range(0,acc.shape[0]-2,1)\n",
    "x_skip = range(0,acc.shape[0]-2,2)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[0].plot(x_skip,acc[2::2,i],'o',color=col[i,:], label='_nolegend_')\n",
    "    ax[0].plot(x,acc[2:,i],'-',color=col[i,:])\n",
    "\n",
    "    if i == 0:\n",
    "        ls = 's--'\n",
    "    else:\n",
    "        ls = 's-'\n",
    "    ax[1].plot(x_skip,recal_acc[mask,i], ls,color=col[i,:])\n",
    "\n",
    "    if i > 0:\n",
    "        ax[2].plot(x_skip,adapt_acc[mask,i], 'v-',color=col[i,:])\n",
    "\n",
    "    ax[i].set_ylim([0,100])\n",
    "\n",
    "ax[0].legend(['LDA','MLP','CNN'])\n",
    "ax[1].legend(['r-LDA','r-MLP','r-CNN'])\n",
    "ax[2].legend(['a-MLP','a-CNN'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96e4d54467b05e62951c9fd7929782b99429e3b62c1a3b146d4f3dbf79f907e6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('adapt_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
